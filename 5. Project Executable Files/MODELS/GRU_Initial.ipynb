{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d3c21f-bb02-4f3f-ac53-41ebfa77843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, Input\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eae8a5d-e99f-4357-8160-37b391c650d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV file\n",
    "file_path = 'GlobalTemperatures.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Impute LandAverageTemperature and LandAverageTemperatureUncertainty with mean\n",
    "df['LandAverageTemperature'].fillna(df['LandAverageTemperature'].mean(), inplace=True)\n",
    "df['LandAverageTemperatureUncertainty'].fillna(df['LandAverageTemperatureUncertainty'].mean(), inplace=True)\n",
    "\n",
    "# For columns with 1200 missing values, drop those rows\n",
    "cols_to_dropna = ['LandMaxTemperature', 'LandMaxTemperatureUncertainty', 'LandMinTemperature', 'LandMinTemperatureUncertainty', 'LandAndOceanAverageTemperature', 'LandAndOceanAverageTemperatureUncertainty']\n",
    "df.dropna(subset=cols_to_dropna, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2db283bf-dc44-4aef-a6f9-f9cd3592b89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1593, 9, 1)\n",
      "X_test_scaled shape: (399, 9, 1)\n",
      "y_train_scaled shape: (1593, 1)\n",
      "y_test_scaled shape: (399, 1)\n"
     ]
    }
   ],
   "source": [
    "# Add Year and Month columns based on 'dt' column\n",
    "df['Year'] = pd.to_datetime(df['dt']).dt.year\n",
    "df['Month'] = pd.to_datetime(df['dt']).dt.month\n",
    "\n",
    "# Prepare X (features) and y (target)\n",
    "X = df.drop(['LandAverageTemperature', 'dt'], axis=1)\n",
    "y = df['LandAverageTemperature']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale X and y using MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler_x.fit_transform(X_train)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "# Only transform the testing data\n",
    "X_test_scaled = scaler_x.transform(X_test)\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Reshape X_train_scaled and X_test_scaled for RNN input\n",
    "X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"X_test_scaled shape:\", X_test_scaled.shape)\n",
    "print(\"y_train_scaled shape:\", y_train_scaled.shape)\n",
    "print(\"y_test_scaled shape:\", y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3177c5d-8009-4cb7-9b97-246797ce5b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">30,900</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">60,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │          \u001b[38;5;34m30,900\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m60,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,601</span> (357.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91,601\u001b[0m (357.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,601</span> (357.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m91,601\u001b[0m (357.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the GRU model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "model.add(GRU(100, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca70bef7-b0eb-43fa-bdcb-abd430e6a1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 - 3s - 73ms/step - loss: 0.0910 - val_loss: 0.0426\n",
      "Epoch 2/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0331 - val_loss: 0.0119\n",
      "Epoch 3/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0168 - val_loss: 0.0094\n",
      "Epoch 4/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0146 - val_loss: 0.0093\n",
      "Epoch 5/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0131 - val_loss: 0.0068\n",
      "Epoch 6/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0121 - val_loss: 0.0059\n",
      "Epoch 7/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0109 - val_loss: 0.0064\n",
      "Epoch 8/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0102 - val_loss: 0.0056\n",
      "Epoch 9/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0089 - val_loss: 0.0040\n",
      "Epoch 10/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0081 - val_loss: 0.0045\n",
      "Epoch 11/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0067 - val_loss: 0.0034\n",
      "Epoch 12/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0061 - val_loss: 0.0021\n",
      "Epoch 13/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 14/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 15/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0053 - val_loss: 0.0013\n",
      "Epoch 16/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 17/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 18/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 19/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0046 - val_loss: 0.0019\n",
      "Epoch 20/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 21/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 22/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 23/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 24/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 25/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 26/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 27/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 28/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 29/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 30/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0035 - val_loss: 0.0010\n",
      "Epoch 31/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0032 - val_loss: 9.7896e-04\n",
      "Epoch 32/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 33/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 34/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 35/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0035 - val_loss: 9.4697e-04\n",
      "Epoch 36/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 37/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 39/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 40/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 41/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 42/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0029 - val_loss: 9.0093e-04\n",
      "Epoch 43/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0032 - val_loss: 9.2105e-04\n",
      "Epoch 45/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0027 - val_loss: 9.6283e-04\n",
      "Epoch 47/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 48/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 49/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0029 - val_loss: 9.3009e-04\n",
      "Epoch 50/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 52/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 53/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0029 - val_loss: 8.4341e-04\n",
      "Epoch 54/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0027 - val_loss: 8.0544e-04\n",
      "Epoch 55/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 56/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0024 - val_loss: 9.8236e-04\n",
      "Epoch 57/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 58/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 59/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 60/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0024 - val_loss: 8.2121e-04\n",
      "Epoch 61/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 62/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0024 - val_loss: 8.8892e-04\n",
      "Epoch 63/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 64/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 65/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 66/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0024 - val_loss: 8.6124e-04\n",
      "Epoch 67/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0022 - val_loss: 8.2283e-04\n",
      "Epoch 68/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0022 - val_loss: 8.8297e-04\n",
      "Epoch 69/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0020 - val_loss: 9.4896e-04\n",
      "Epoch 70/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0019 - val_loss: 9.8952e-04\n",
      "Epoch 71/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0026 - val_loss: 8.7646e-04\n",
      "Epoch 72/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 73/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0018 - val_loss: 8.4364e-04\n",
      "Epoch 74/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0020 - val_loss: 8.4678e-04\n",
      "Epoch 75/100\n",
      "40/40 - 0s - 10ms/step - loss: 0.0021 - val_loss: 7.7386e-04\n",
      "Epoch 76/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0019 - val_loss: 9.8319e-04\n",
      "Epoch 77/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 78/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 79/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0020 - val_loss: 7.5317e-04\n",
      "Epoch 81/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 82/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0019 - val_loss: 9.6907e-04\n",
      "Epoch 83/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0018 - val_loss: 6.8114e-04\n",
      "Epoch 84/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0018 - val_loss: 8.2837e-04\n",
      "Epoch 85/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0018 - val_loss: 9.2491e-04\n",
      "Epoch 86/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0017 - val_loss: 6.7097e-04\n",
      "Epoch 87/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0019 - val_loss: 6.8682e-04\n",
      "Epoch 88/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0018 - val_loss: 6.6379e-04\n",
      "Epoch 89/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0018 - val_loss: 8.9880e-04\n",
      "Epoch 90/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0017 - val_loss: 5.2827e-04\n",
      "Epoch 91/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 92/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0017 - val_loss: 8.4053e-04\n",
      "Epoch 93/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0017 - val_loss: 7.0594e-04\n",
      "Epoch 94/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0017 - val_loss: 6.7208e-04\n",
      "Epoch 95/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0016 - val_loss: 5.4771e-04\n",
      "Epoch 96/100\n",
      "40/40 - 0s - 9ms/step - loss: 0.0017 - val_loss: 9.7053e-04\n",
      "Epoch 97/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0018 - val_loss: 7.2529e-04\n",
      "Epoch 98/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0017 - val_loss: 5.6472e-04\n",
      "Epoch 99/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0016 - val_loss: 4.6698e-04\n",
      "Epoch 100/100\n",
      "40/40 - 0s - 8ms/step - loss: 0.0017 - val_loss: 9.7285e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train_scaled, epochs=100, batch_size=32, validation_split=0.2,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "228f1a7e-0580-4d6a-a09c-af109a0cb65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predictions = scaler_y.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5532b73-37c4-4d49-a044-9765c3b40d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 3.88, Predicted: 3.7594563961029053\n",
      "Actual: 8.689, Predicted: 8.816386222839355\n",
      "Actual: 13.622, Predicted: 13.977884292602539\n",
      "Actual: 2.335, Predicted: 2.938523054122925\n",
      "Actual: 5.952999999999999, Predicted: 6.066404342651367\n",
      "Actual: 4.869, Predicted: 4.831769943237305\n",
      "Actual: 14.768, Predicted: 15.103588104248047\n",
      "Actual: 7.423999999999999, Predicted: 7.708240509033203\n",
      "Actual: 4.103, Predicted: 3.860334873199463\n",
      "Actual: 4.519, Predicted: 4.503964424133301\n",
      "Actual: 14.021, Predicted: 14.504230499267578\n",
      "Actual: 14.034, Predicted: 14.371270179748535\n",
      "Actual: 4.85, Predicted: 5.267367839813232\n",
      "Actual: 9.453, Predicted: 9.792223930358887\n",
      "Actual: 6.222, Predicted: 6.09636116027832\n",
      "Actual: 14.445, Predicted: 14.871575355529785\n",
      "Actual: 11.062, Predicted: 10.831170082092285\n",
      "Actual: 2.455, Predicted: 2.8312814235687256\n",
      "Actual: 6.273, Predicted: 6.277585029602051\n",
      "Actual: 4.303, Predicted: 4.081684112548828\n",
      "Actual: 5.066, Predicted: 5.073912620544434\n",
      "Actual: 10.941999999999998, Predicted: 11.351391792297363\n",
      "Actual: 4.859, Predicted: 4.516473770141602\n",
      "Actual: 3.629, Predicted: 3.7407119274139404\n",
      "Actual: 4.924, Predicted: 4.498218059539795\n",
      "Actual: 12.048, Predicted: 12.481077194213867\n",
      "Actual: 13.157, Predicted: 13.516927719116211\n",
      "Actual: 10.944, Predicted: 11.22859001159668\n",
      "Actual: 9.264, Predicted: 9.622065544128418\n",
      "Actual: 8.498999999999999, Predicted: 9.013699531555176\n",
      "Actual: 5.902, Predicted: 5.615669250488281\n",
      "Actual: 13.775, Predicted: 14.219683647155762\n",
      "Actual: 2.488, Predicted: 2.7147772312164307\n",
      "Actual: 3.628, Predicted: 3.9482274055480957\n",
      "Actual: 14.201, Predicted: 14.65699291229248\n",
      "Actual: 13.22, Predicted: 13.79955768585205\n",
      "Actual: 5.186, Predicted: 4.275536060333252\n",
      "Actual: 9.338, Predicted: 9.767325401306152\n",
      "Actual: 3.422, Predicted: 3.698789119720459\n",
      "Actual: 5.118, Predicted: 5.055547714233398\n",
      "Actual: 13.687, Predicted: 14.166502952575684\n",
      "Actual: 3.069, Predicted: 3.048038959503174\n",
      "Actual: 12.324000000000002, Predicted: 12.940007209777832\n",
      "Actual: 13.807, Predicted: 14.35654354095459\n",
      "Actual: 1.836, Predicted: 2.0403666496276855\n",
      "Actual: 5.702000000000001, Predicted: 5.699674606323242\n",
      "Actual: 13.401, Predicted: 14.321887016296387\n",
      "Actual: 11.892, Predicted: 12.114978790283203\n",
      "Actual: 12.984000000000002, Predicted: 12.568432807922363\n",
      "Actual: 8.542, Predicted: 7.529179573059082\n",
      "Actual: 5.031000000000001, Predicted: 4.988864421844482\n",
      "Actual: 11.514, Predicted: 11.636387825012207\n",
      "Actual: 4.8660000000000005, Predicted: 4.982329845428467\n",
      "Actual: 12.095999999999998, Predicted: 12.726944923400879\n",
      "Actual: 14.285, Predicted: 14.550671577453613\n",
      "Actual: 3.2430000000000003, Predicted: 3.517890453338623\n",
      "Actual: 9.735, Predicted: 9.91358470916748\n",
      "Actual: 8.511000000000001, Predicted: 8.803279876708984\n",
      "Actual: 12.856, Predicted: 13.302123069763184\n",
      "Actual: 14.144, Predicted: 14.703448295593262\n",
      "Actual: 3.656, Predicted: 3.795637845993042\n",
      "Actual: 13.164, Predicted: 12.908788681030273\n",
      "Actual: 12.093, Predicted: 12.70384407043457\n",
      "Actual: 2.781, Predicted: 3.132697343826294\n",
      "Actual: 11.831, Predicted: 12.454916954040527\n",
      "Actual: 13.405, Predicted: 13.431310653686523\n",
      "Actual: 13.752, Predicted: 14.12394905090332\n",
      "Actual: 14.052, Predicted: 14.525894165039062\n",
      "Actual: 9.488, Predicted: 9.704812049865723\n",
      "Actual: 4.8260000000000005, Predicted: 4.978863716125488\n",
      "Actual: 13.807, Predicted: 14.24794864654541\n",
      "Actual: 5.89, Predicted: 5.799130439758301\n",
      "Actual: 4.959, Predicted: 4.963900089263916\n",
      "Actual: 14.392, Predicted: 14.860836029052734\n",
      "Actual: 8.25, Predicted: 7.131617069244385\n",
      "Actual: 14.742, Predicted: 15.043719291687012\n",
      "Actual: 8.443999999999999, Predicted: 9.103375434875488\n",
      "Actual: 3.1950000000000003, Predicted: 3.4499545097351074\n",
      "Actual: 11.604, Predicted: 12.06304931640625\n",
      "Actual: 13.105, Predicted: 13.599597930908203\n",
      "Actual: 13.412, Predicted: 13.96937084197998\n",
      "Actual: 7.9209999999999985, Predicted: 7.45321798324585\n",
      "Actual: 2.052, Predicted: 2.998382329940796\n",
      "Actual: 3.5980000000000003, Predicted: 3.6356914043426514\n",
      "Actual: 14.138, Predicted: 14.505687713623047\n",
      "Actual: 14.375, Predicted: 14.786020278930664\n",
      "Actual: 9.552, Predicted: 9.8191499710083\n",
      "Actual: 4.134, Predicted: 4.144768238067627\n",
      "Actual: 11.155, Predicted: 11.74049186706543\n",
      "Actual: 9.729, Predicted: 10.253512382507324\n",
      "Actual: 3.306, Predicted: 3.391091823577881\n",
      "Actual: 14.140999999999998, Predicted: 14.5473051071167\n",
      "Actual: 14.377, Predicted: 14.781240463256836\n",
      "Actual: 13.796, Predicted: 14.441164016723633\n",
      "Actual: 9.671, Predicted: 9.99512767791748\n",
      "Actual: 7.329999999999999, Predicted: 7.831398010253906\n",
      "Actual: 6.404, Predicted: 6.617987155914307\n",
      "Actual: 1.793, Predicted: 2.7553837299346924\n",
      "Actual: 10.787999999999998, Predicted: 10.889663696289062\n",
      "Actual: 14.630999999999998, Predicted: 14.984869956970215\n",
      "Actual: 14.188, Predicted: 14.65914535522461\n",
      "Actual: 7.738999999999999, Predicted: 7.793575763702393\n",
      "Actual: 2.228, Predicted: 3.6043431758880615\n",
      "Actual: 8.280999999999999, Predicted: 8.575737953186035\n",
      "Actual: 11.984000000000002, Predicted: 12.252506256103516\n",
      "Actual: 3.458, Predicted: 3.380674123764038\n",
      "Actual: 6.295, Predicted: 6.309504985809326\n",
      "Actual: 2.291, Predicted: 2.581777334213257\n",
      "Actual: 9.006, Predicted: 7.624755859375\n",
      "Actual: 13.351, Predicted: 14.007500648498535\n",
      "Actual: 14.144, Predicted: 14.544966697692871\n",
      "Actual: 14.37, Predicted: 14.742339134216309\n",
      "Actual: 6.377999999999999, Predicted: 6.220633506774902\n",
      "Actual: 9.584, Predicted: 10.17738151550293\n",
      "Actual: 14.255999999999998, Predicted: 14.790141105651855\n",
      "Actual: 1.966, Predicted: 2.47609543800354\n",
      "Actual: 13.514, Predicted: 13.9985990524292\n",
      "Actual: 4.259, Predicted: 4.173436164855957\n",
      "Actual: 2.713, Predicted: 2.9139018058776855\n",
      "Actual: 12.153, Predicted: 12.73501205444336\n",
      "Actual: 9.281, Predicted: 10.04865837097168\n",
      "Actual: 11.763, Predicted: 12.362312316894531\n",
      "Actual: 4.016, Predicted: 4.018568515777588\n",
      "Actual: 14.505, Predicted: 14.900337219238281\n",
      "Actual: 3.604, Predicted: 3.3724422454833984\n",
      "Actual: 3.921, Predicted: 3.8991968631744385\n",
      "Actual: 3.196, Predicted: 3.2117550373077393\n",
      "Actual: 2.172, Predicted: 2.4259555339813232\n",
      "Actual: 9.516, Predicted: 9.851895332336426\n",
      "Actual: 14.231, Predicted: 14.717541694641113\n",
      "Actual: 11.685, Predicted: 12.069185256958008\n",
      "Actual: 11.354, Predicted: 12.010061264038086\n",
      "Actual: 3.071, Predicted: 3.0705485343933105\n",
      "Actual: 14.798, Predicted: 15.121447563171387\n",
      "Actual: 12.872, Predicted: 13.266161918640137\n",
      "Actual: 11.097, Predicted: 11.816339492797852\n",
      "Actual: 5.077, Predicted: 5.152327060699463\n",
      "Actual: 5.809, Predicted: 4.464216232299805\n",
      "Actual: 8.722000000000001, Predicted: 8.486202239990234\n",
      "Actual: 8.991999999999997, Predicted: 9.361449241638184\n",
      "Actual: 7.1560000000000015, Predicted: 7.396112442016602\n",
      "Actual: 3.832, Predicted: 3.744135856628418\n",
      "Actual: 3.155, Predicted: 3.0786609649658203\n",
      "Actual: 3.3360000000000003, Predicted: 3.570974588394165\n",
      "Actual: 11.845, Predicted: 12.382954597473145\n",
      "Actual: 14.429, Predicted: 14.85028076171875\n",
      "Actual: 2.077, Predicted: 1.910786509513855\n",
      "Actual: 3.5, Predicted: 3.4639790058135986\n",
      "Actual: 11.729, Predicted: 12.40457534790039\n",
      "Actual: 3.092, Predicted: 3.260591506958008\n",
      "Actual: 6.3, Predicted: 6.24140739440918\n",
      "Actual: 13.395, Predicted: 13.742538452148438\n",
      "Actual: 7.486999999999999, Predicted: 6.624205112457275\n",
      "Actual: 3.24, Predicted: 3.413588523864746\n",
      "Actual: 13.23, Predicted: 13.59154987335205\n",
      "Actual: 14.298, Predicted: 14.530085563659668\n",
      "Actual: 1.003, Predicted: 2.2792532444000244\n",
      "Actual: 2.7060000000000004, Predicted: 3.01289963722229\n",
      "Actual: 2.466, Predicted: 2.729665756225586\n",
      "Actual: 2.611, Predicted: 2.7531795501708984\n",
      "Actual: 4.622, Predicted: 4.180708885192871\n",
      "Actual: 4.94, Predicted: 5.0398783683776855\n",
      "Actual: 13.537, Predicted: 13.560271263122559\n",
      "Actual: 4.811, Predicted: 4.821100234985352\n",
      "Actual: 2.286, Predicted: 2.30855131149292\n",
      "Actual: 3.8630000000000004, Predicted: 4.057898044586182\n",
      "Actual: 13.347, Predicted: 13.781797409057617\n",
      "Actual: 9.077, Predicted: 9.042438507080078\n",
      "Actual: 9.157, Predicted: 9.609917640686035\n",
      "Actual: 9.67, Predicted: 10.111161231994629\n",
      "Actual: 3.5, Predicted: 3.843350887298584\n",
      "Actual: 11.759, Predicted: 12.046112060546875\n",
      "Actual: 13.505999999999998, Predicted: 14.287141799926758\n",
      "Actual: 11.386, Predicted: 12.207911491394043\n",
      "Actual: 14.122, Predicted: 14.555594444274902\n",
      "Actual: 14.408, Predicted: 14.86853313446045\n",
      "Actual: 11.743, Predicted: 12.057829856872559\n",
      "Actual: 11.235, Predicted: 11.532403945922852\n",
      "Actual: 11.284999999999998, Predicted: 11.689464569091797\n",
      "Actual: 4.059, Predicted: 4.107252597808838\n",
      "Actual: 5.399, Predicted: 5.283646106719971\n",
      "Actual: 6.205, Predicted: 6.172904014587402\n",
      "Actual: 6.74, Predicted: 6.760359287261963\n",
      "Actual: 7.748999999999999, Predicted: 7.953042507171631\n",
      "Actual: 3.513, Predicted: 3.6979918479919434\n",
      "Actual: 10.69, Predicted: 10.964496612548828\n",
      "Actual: 13.331, Predicted: 13.73569393157959\n",
      "Actual: 5.097, Predicted: 5.030468463897705\n",
      "Actual: 13.713, Predicted: 14.279117584228516\n",
      "Actual: 1.941, Predicted: 2.2964634895324707\n",
      "Actual: 4.9190000000000005, Predicted: 5.100746154785156\n",
      "Actual: 13.557, Predicted: 14.006406784057617\n",
      "Actual: 2.71, Predicted: 3.1002347469329834\n",
      "Actual: 4.327999999999999, Predicted: 4.342145919799805\n",
      "Actual: 9.056, Predicted: 9.181544303894043\n",
      "Actual: 2.857, Predicted: 3.378561019897461\n",
      "Actual: 5.272, Predicted: 4.797040939331055\n",
      "Actual: 4.6850000000000005, Predicted: 5.082814693450928\n",
      "Actual: 6.397, Predicted: 6.418498992919922\n",
      "Actual: 7.185999999999999, Predicted: 6.941920757293701\n",
      "Actual: 13.484000000000002, Predicted: 14.305431365966797\n",
      "Actual: 14.223, Predicted: 14.806573867797852\n",
      "Actual: 10.611, Predicted: 10.8983154296875\n",
      "Actual: 9.627, Predicted: 10.194053649902344\n",
      "Actual: 3.14, Predicted: 4.541012763977051\n",
      "Actual: 14.238, Predicted: 14.270727157592773\n",
      "Actual: 8.58, Predicted: 6.486827850341797\n",
      "Actual: 11.222, Predicted: 11.807330131530762\n",
      "Actual: 11.797, Predicted: 12.269438743591309\n",
      "Actual: 13.964, Predicted: 14.470664024353027\n",
      "Actual: 3.4560000000000004, Predicted: 3.6587934494018555\n",
      "Actual: 14.468, Predicted: 15.011219024658203\n",
      "Actual: 7.767999999999998, Predicted: 7.927897930145264\n",
      "Actual: 8.838, Predicted: 9.10641860961914\n",
      "Actual: 6.047999999999999, Predicted: 6.199310779571533\n",
      "Actual: 11.925, Predicted: 12.369974136352539\n",
      "Actual: 10.898, Predicted: 10.98454475402832\n",
      "Actual: 14.242, Predicted: 14.439074516296387\n",
      "Actual: 13.161, Predicted: 13.791224479675293\n",
      "Actual: 3.104, Predicted: 3.188997983932495\n",
      "Actual: 5.596, Predicted: 5.414260387420654\n",
      "Actual: 13.308, Predicted: 13.86296558380127\n",
      "Actual: 10.851, Predicted: 10.332721710205078\n",
      "Actual: 8.594999999999999, Predicted: 8.917339324951172\n",
      "Actual: 5.245, Predicted: 5.417327880859375\n",
      "Actual: 7.487, Predicted: 7.6204142570495605\n",
      "Actual: 11.308, Predicted: 11.447809219360352\n",
      "Actual: 5.915, Predicted: 5.851038455963135\n",
      "Actual: 13.204, Predicted: 13.708263397216797\n",
      "Actual: 6.377999999999999, Predicted: 6.449681282043457\n",
      "Actual: 9.55, Predicted: 9.80628490447998\n",
      "Actual: 6.356, Predicted: 6.305933475494385\n",
      "Actual: 3.333, Predicted: 3.4531822204589844\n",
      "Actual: 8.870999999999997, Predicted: 9.107033729553223\n",
      "Actual: 2.616, Predicted: 2.764568567276001\n",
      "Actual: 3.3960000000000004, Predicted: 3.6049411296844482\n",
      "Actual: 2.989, Predicted: 3.1396923065185547\n",
      "Actual: 3.33, Predicted: 3.4682559967041016\n",
      "Actual: 12.127999999999998, Predicted: 12.59244441986084\n",
      "Actual: 9.196, Predicted: 9.422836303710938\n",
      "Actual: 13.217, Predicted: 14.109121322631836\n",
      "Actual: 14.339, Predicted: 14.696687698364258\n",
      "Actual: 14.274, Predicted: 14.648506164550781\n",
      "Actual: 4.6, Predicted: 4.6530680656433105\n",
      "Actual: 7.6839999999999975, Predicted: 7.716282367706299\n",
      "Actual: 9.021, Predicted: 9.310296058654785\n",
      "Actual: 13.531, Predicted: 14.049674034118652\n",
      "Actual: 13.577, Predicted: 14.152298927307129\n",
      "Actual: 3.005, Predicted: 3.2072267532348633\n",
      "Actual: 15.212999999999997, Predicted: 15.424554824829102\n",
      "Actual: 12.146, Predicted: 12.718243598937988\n",
      "Actual: 7.617999999999999, Predicted: 7.937995433807373\n",
      "Actual: 14.827, Predicted: 15.138331413269043\n",
      "Actual: 11.989999999999998, Predicted: 12.445501327514648\n",
      "Actual: 13.365, Predicted: 13.857749938964844\n",
      "Actual: 10.803, Predicted: 11.173371315002441\n",
      "Actual: 11.239, Predicted: 11.692181587219238\n",
      "Actual: 3.559, Predicted: 3.606384038925171\n",
      "Actual: 14.019, Predicted: 13.365589141845703\n",
      "Actual: 13.824000000000002, Predicted: 14.26489543914795\n",
      "Actual: 11.478, Predicted: 11.384286880493164\n",
      "Actual: 2.0540000000000003, Predicted: 2.419600248336792\n",
      "Actual: 7.906999999999999, Predicted: 8.172369956970215\n",
      "Actual: 5.01, Predicted: 4.466374397277832\n",
      "Actual: 8.442, Predicted: 8.581697463989258\n",
      "Actual: 13.294, Predicted: 13.977060317993164\n",
      "Actual: 4.152, Predicted: 2.855058431625366\n",
      "Actual: 8.69, Predicted: 8.916653633117676\n",
      "Actual: 2.627, Predicted: 2.629880666732788\n",
      "Actual: 9.378, Predicted: 9.679560661315918\n",
      "Actual: 13.77, Predicted: 14.44946002960205\n",
      "Actual: 4.222, Predicted: 4.424188613891602\n",
      "Actual: 14.226, Predicted: 14.52269172668457\n",
      "Actual: 9.12, Predicted: 9.04370403289795\n",
      "Actual: 3.069, Predicted: 3.0822839736938477\n",
      "Actual: 4.257, Predicted: 4.518063068389893\n",
      "Actual: 4.538, Predicted: 4.367140293121338\n",
      "Actual: 6.738, Predicted: 6.73516321182251\n",
      "Actual: 3.743, Predicted: 3.9777164459228516\n",
      "Actual: 14.06, Predicted: 14.52901554107666\n",
      "Actual: 15.160999999999998, Predicted: 15.39119815826416\n",
      "Actual: 11.977, Predicted: 12.220491409301758\n",
      "Actual: 3.457, Predicted: 3.204239845275879\n",
      "Actual: 4.31, Predicted: 4.704221248626709\n",
      "Actual: 13.113, Predicted: 13.507585525512695\n",
      "Actual: 2.226, Predicted: 3.9117987155914307\n",
      "Actual: 13.765, Predicted: 14.165440559387207\n",
      "Actual: 2.376, Predicted: 2.7670490741729736\n",
      "Actual: 7.994, Predicted: 7.916193962097168\n",
      "Actual: 3.039, Predicted: 3.2396321296691895\n",
      "Actual: 14.145, Predicted: 14.531242370605469\n",
      "Actual: 11.771999999999998, Predicted: 12.169729232788086\n",
      "Actual: 14.351, Predicted: 14.732024192810059\n",
      "Actual: 8.535, Predicted: 8.91186237335205\n",
      "Actual: 5.731, Predicted: 5.802056789398193\n",
      "Actual: 12.039, Predicted: 12.669703483581543\n",
      "Actual: 2.506, Predicted: 2.9988584518432617\n",
      "Actual: 8.247, Predicted: 8.690455436706543\n",
      "Actual: 10.53, Predicted: 10.606557846069336\n",
      "Actual: 3.687, Predicted: 3.8798747062683105\n",
      "Actual: 3.766, Predicted: 3.9312455654144287\n",
      "Actual: 3.7780000000000005, Predicted: 3.913085699081421\n",
      "Actual: 13.932, Predicted: 14.430536270141602\n",
      "Actual: 8.366, Predicted: 8.655587196350098\n",
      "Actual: 3.8220000000000005, Predicted: 3.831502676010132\n",
      "Actual: 5.973, Predicted: 5.743819236755371\n",
      "Actual: 14.512, Predicted: 14.396129608154297\n",
      "Actual: 5.247000000000001, Predicted: 5.2321553230285645\n",
      "Actual: 11.338, Predicted: 11.868877410888672\n",
      "Actual: 3.74, Predicted: 3.72703218460083\n",
      "Actual: 5.827999999999999, Predicted: 5.866176128387451\n",
      "Actual: 3.39, Predicted: 3.3631322383880615\n",
      "Actual: 2.862, Predicted: 3.2319531440734863\n",
      "Actual: 13.297, Predicted: 13.802841186523438\n",
      "Actual: 2.9560000000000004, Predicted: 3.2562341690063477\n",
      "Actual: 8.892000000000001, Predicted: 9.304115295410156\n",
      "Actual: 14.742, Predicted: 15.111490249633789\n",
      "Actual: 11.71, Predicted: 11.826807975769043\n",
      "Actual: 11.861999999999998, Predicted: 12.388059616088867\n",
      "Actual: 1.551, Predicted: 2.3910093307495117\n",
      "Actual: 7.635999999999999, Predicted: 7.41438102722168\n",
      "Actual: 13.698, Predicted: 14.139922142028809\n",
      "Actual: 13.678, Predicted: 14.225279808044434\n",
      "Actual: 13.153, Predicted: 13.69345760345459\n",
      "Actual: 13.691, Predicted: 14.184029579162598\n",
      "Actual: 2.402, Predicted: 2.2694594860076904\n",
      "Actual: 12.199000000000002, Predicted: 12.791679382324219\n",
      "Actual: 4.506, Predicted: 4.411452770233154\n",
      "Actual: 13.298, Predicted: 13.70854377746582\n",
      "Actual: 14.231, Predicted: 14.532504081726074\n",
      "Actual: 8.738, Predicted: 8.519285202026367\n",
      "Actual: 8.679, Predicted: 8.87507438659668\n",
      "Actual: 4.038, Predicted: 4.291975498199463\n",
      "Actual: 14.09, Predicted: 14.53786563873291\n",
      "Actual: 13.214, Predicted: 13.769003868103027\n",
      "Actual: 3.898, Predicted: 3.973848342895508\n",
      "Actual: 13.488, Predicted: 13.894522666931152\n",
      "Actual: 2.008, Predicted: 2.5828449726104736\n",
      "Actual: 9.367, Predicted: 9.549586296081543\n",
      "Actual: 5.671, Predicted: 5.477417945861816\n",
      "Actual: 8.865, Predicted: 8.799227714538574\n",
      "Actual: 13.442, Predicted: 14.119134902954102\n",
      "Actual: 9.232, Predicted: 9.728317260742188\n",
      "Actual: 11.954, Predicted: 12.576080322265625\n",
      "Actual: 12.406, Predicted: 12.925588607788086\n",
      "Actual: 8.173, Predicted: 8.376891136169434\n",
      "Actual: 11.946, Predicted: 12.47719669342041\n",
      "Actual: 13.434, Predicted: 13.887872695922852\n",
      "Actual: 4.9990000000000006, Predicted: 4.966039657592773\n",
      "Actual: 6.814, Predicted: 6.987265586853027\n",
      "Actual: 5.4510000000000005, Predicted: 5.515470027923584\n",
      "Actual: 7.76, Predicted: 7.2273783683776855\n",
      "Actual: 5.318, Predicted: 5.0334553718566895\n",
      "Actual: 8.445, Predicted: 8.718348503112793\n",
      "Actual: 14.139, Predicted: 14.6456880569458\n",
      "Actual: 2.609, Predicted: 2.9742841720581055\n",
      "Actual: 6.183, Predicted: 6.079554080963135\n",
      "Actual: 14.31, Predicted: 14.732697486877441\n",
      "Actual: 14.151, Predicted: 15.015336990356445\n",
      "Actual: 3.491, Predicted: 3.611002206802368\n",
      "Actual: 4.421, Predicted: 4.2744245529174805\n",
      "Actual: 13.836, Predicted: 14.240372657775879\n",
      "Actual: 9.238, Predicted: 9.477690696716309\n",
      "Actual: 5.952000000000001, Predicted: 5.9684553146362305\n",
      "Actual: 5.093, Predicted: 4.199265480041504\n",
      "Actual: 13.223, Predicted: 13.803824424743652\n",
      "Actual: 4.922, Predicted: 3.9897570610046387\n",
      "Actual: 7.561999999999998, Predicted: 7.777388572692871\n",
      "Actual: 11.62, Predicted: 12.102341651916504\n",
      "Actual: 13.547, Predicted: 13.641556739807129\n",
      "Actual: 12.03, Predicted: 12.407747268676758\n",
      "Actual: 14.004, Predicted: 14.379124641418457\n",
      "Actual: 4.704, Predicted: 4.826495170593262\n",
      "Actual: 4.026, Predicted: 4.138742446899414\n",
      "Actual: 8.588999999999999, Predicted: 8.919480323791504\n",
      "Actual: 2.905, Predicted: 3.1862356662750244\n",
      "Actual: 14.349, Predicted: 14.7064790725708\n",
      "Actual: 8.434, Predicted: 9.012399673461914\n",
      "Actual: 13.296, Predicted: 13.63119888305664\n",
      "Actual: 3.265, Predicted: 3.4603776931762695\n",
      "Actual: 14.059, Predicted: 14.55638313293457\n",
      "Actual: 11.665, Predicted: 11.917662620544434\n",
      "Actual: 11.867, Predicted: 12.439200401306152\n",
      "Actual: 13.475, Predicted: 14.006149291992188\n",
      "Actual: 8.097999999999999, Predicted: 8.259429931640625\n",
      "Actual: 13.789, Predicted: 14.312054634094238\n",
      "Actual: 2.492, Predicted: 3.0697872638702393\n",
      "Actual: 3.7850000000000006, Predicted: 3.8964807987213135\n",
      "Actual: 13.896, Predicted: 14.483748435974121\n",
      "Actual: 5.405, Predicted: 5.380002498626709\n",
      "Actual: 13.478, Predicted: 14.044260025024414\n",
      "Actual: 2.9410000000000003, Predicted: 3.2347044944763184\n",
      "Actual: 2.6790000000000003, Predicted: 3.042900562286377\n",
      "Actual: 5.524, Predicted: 5.662787914276123\n",
      "Actual: 13.769, Predicted: 14.24460506439209\n",
      "Actual: 9.096, Predicted: 8.681290626525879\n",
      "Actual: 2.71, Predicted: 2.895235061645508\n",
      "Actual: 12.03, Predicted: 12.469658851623535\n",
      "Actual: 2.082, Predicted: 2.143207550048828\n"
     ]
    }
   ],
   "source": [
    "# Compare predictions with actual values\n",
    "actual = scaler_y.inverse_transform(y_test_scaled)\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"Actual: {actual[i][0]}, Predicted: {predictions[i][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41e6359-94e8-460d-8646-261b747ec044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.35085869968146616\n",
      "Mean Squared Error (MSE): 0.19697589123732714\n",
      "Root Mean Squared Error (RMSE): 0.4438196607151683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(actual, predictions)\n",
    "mse = mean_squared_error(actual, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
