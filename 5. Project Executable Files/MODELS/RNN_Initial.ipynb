{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca5a5499-930a-4bfb-806e-330937616574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout, Input\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b99487b9-cf34-45cd-85ca-6fdd53eb6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV file\n",
    "file_path = 'GlobalTemperatures.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Impute LandAverageTemperature and LandAverageTemperatureUncertainty with mean\n",
    "df['LandAverageTemperature'].fillna(df['LandAverageTemperature'].mean(), inplace=True)\n",
    "df['LandAverageTemperatureUncertainty'].fillna(df['LandAverageTemperatureUncertainty'].mean(), inplace=True)\n",
    "\n",
    "# For columns with 1200 missing values, drop those rows\n",
    "cols_to_dropna = ['LandMaxTemperature', 'LandMaxTemperatureUncertainty', 'LandMinTemperature', 'LandMinTemperatureUncertainty', 'LandAndOceanAverageTemperature', 'LandAndOceanAverageTemperatureUncertainty']\n",
    "df.dropna(subset=cols_to_dropna, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63bd3778-f278-47ac-b08b-6c85c12ba48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1593, 9, 1)\n",
      "X_test_scaled shape: (399, 9, 1)\n",
      "y_train_scaled shape: (1593, 1)\n",
      "y_test_scaled shape: (399, 1)\n"
     ]
    }
   ],
   "source": [
    "# Add Year and Month columns based on 'dt' column\n",
    "df['Year'] = pd.to_datetime(df['dt']).dt.year\n",
    "df['Month'] = pd.to_datetime(df['dt']).dt.month\n",
    "\n",
    "# Prepare X (features) and y (target)\n",
    "X = df.drop(['LandAverageTemperature', 'dt'], axis=1)\n",
    "y = df['LandAverageTemperature']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale X and y using MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler_x.fit_transform(X_train)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "# Only transform the testing data\n",
    "X_test_scaled = scaler_x.transform(X_test)\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Reshape X_train_scaled and X_test_scaled for RNN input\n",
    "X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"X_test_scaled shape:\", X_test_scaled.shape)\n",
    "print(\"y_train_scaled shape:\", y_train_scaled.shape)\n",
    "print(\"y_test_scaled shape:\", y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1518f7e2-4ad9-4e86-b4be-014f0bf1a462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │          \u001b[38;5;34m10,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m20,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,401</span> (118.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,401\u001b[0m (118.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,401</span> (118.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,401\u001b[0m (118.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "model.add(SimpleRNN(100, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f061147a-db3e-4c3a-a27d-730b5ae78164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 - 2s - 52ms/step - loss: 0.0426 - val_loss: 9.7061e-04\n",
      "Epoch 2/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0093 - val_loss: 5.4814e-04\n",
      "Epoch 3/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0075 - val_loss: 0.0013\n",
      "Epoch 4/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0066 - val_loss: 3.6992e-04\n",
      "Epoch 5/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0057 - val_loss: 5.6041e-04\n",
      "Epoch 6/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0060 - val_loss: 7.9040e-04\n",
      "Epoch 7/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0059 - val_loss: 0.0015\n",
      "Epoch 8/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 9/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0051 - val_loss: 5.6402e-04\n",
      "Epoch 10/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0045 - val_loss: 8.2935e-04\n",
      "Epoch 11/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0048 - val_loss: 2.2765e-04\n",
      "Epoch 12/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 13/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 14/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0039 - val_loss: 4.3582e-04\n",
      "Epoch 15/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 16/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0046 - val_loss: 0.0019\n",
      "Epoch 17/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 18/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0038 - val_loss: 2.1721e-04\n",
      "Epoch 19/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 20/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0030 - val_loss: 9.5300e-04\n",
      "Epoch 21/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 22/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 23/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0034 - val_loss: 2.3302e-04\n",
      "Epoch 24/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0028 - val_loss: 2.3325e-04\n",
      "Epoch 25/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0029 - val_loss: 2.2619e-04\n",
      "Epoch 26/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0027 - val_loss: 5.2802e-04\n",
      "Epoch 27/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0030 - val_loss: 6.2872e-04\n",
      "Epoch 28/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0029 - val_loss: 5.1692e-04\n",
      "Epoch 29/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0024 - val_loss: 2.4067e-04\n",
      "Epoch 30/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0026 - val_loss: 9.1217e-04\n",
      "Epoch 31/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0027 - val_loss: 3.2208e-04\n",
      "Epoch 32/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0028 - val_loss: 7.2335e-04\n",
      "Epoch 33/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0026 - val_loss: 5.0584e-04\n",
      "Epoch 34/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0024 - val_loss: 5.1506e-04\n",
      "Epoch 35/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 36/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 37/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0024 - val_loss: 4.8710e-04\n",
      "Epoch 38/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 39/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0028 - val_loss: 8.3548e-04\n",
      "Epoch 40/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 41/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0024 - val_loss: 3.0234e-04\n",
      "Epoch 42/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 43/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0020 - val_loss: 7.0466e-04\n",
      "Epoch 44/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0021 - val_loss: 8.8766e-04\n",
      "Epoch 45/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0019 - val_loss: 2.2698e-04\n",
      "Epoch 46/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 47/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0023 - val_loss: 2.6374e-04\n",
      "Epoch 48/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0020 - val_loss: 5.0725e-04\n",
      "Epoch 49/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0019 - val_loss: 2.0431e-04\n",
      "Epoch 50/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0019 - val_loss: 2.1689e-04\n",
      "Epoch 52/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0020 - val_loss: 3.2696e-04\n",
      "Epoch 53/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0019 - val_loss: 5.7120e-04\n",
      "Epoch 54/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0015 - val_loss: 2.5186e-04\n",
      "Epoch 55/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0017 - val_loss: 4.6942e-04\n",
      "Epoch 56/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0018 - val_loss: 6.3432e-04\n",
      "Epoch 57/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0016 - val_loss: 3.3588e-04\n",
      "Epoch 58/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0019 - val_loss: 5.3448e-04\n",
      "Epoch 59/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0018 - val_loss: 5.9301e-04\n",
      "Epoch 60/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0016 - val_loss: 2.7294e-04\n",
      "Epoch 61/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0015 - val_loss: 4.9472e-04\n",
      "Epoch 62/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 63/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 64/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0015 - val_loss: 2.5807e-04\n",
      "Epoch 65/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 66/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0015 - val_loss: 3.5113e-04\n",
      "Epoch 67/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0016 - val_loss: 2.5687e-04\n",
      "Epoch 68/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0014 - val_loss: 6.2903e-04\n",
      "Epoch 69/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0014 - val_loss: 3.4157e-04\n",
      "Epoch 70/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 71/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0014 - val_loss: 1.6457e-04\n",
      "Epoch 72/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0014 - val_loss: 8.4329e-04\n",
      "Epoch 73/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0013 - val_loss: 4.6168e-04\n",
      "Epoch 74/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0014 - val_loss: 3.5006e-04\n",
      "Epoch 75/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0017 - val_loss: 5.9448e-04\n",
      "Epoch 76/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0015 - val_loss: 3.4178e-04\n",
      "Epoch 77/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0014 - val_loss: 1.5855e-04\n",
      "Epoch 78/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0015 - val_loss: 8.6485e-04\n",
      "Epoch 79/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0013 - val_loss: 1.8000e-04\n",
      "Epoch 80/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0015 - val_loss: 4.2587e-04\n",
      "Epoch 81/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0013 - val_loss: 5.9898e-04\n",
      "Epoch 82/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0013 - val_loss: 3.2764e-04\n",
      "Epoch 83/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0012 - val_loss: 1.8054e-04\n",
      "Epoch 84/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0014 - val_loss: 2.3084e-04\n",
      "Epoch 85/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0013 - val_loss: 2.2431e-04\n",
      "Epoch 86/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0012 - val_loss: 4.7318e-04\n",
      "Epoch 87/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0012 - val_loss: 1.8191e-04\n",
      "Epoch 88/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0011 - val_loss: 3.7582e-04\n",
      "Epoch 89/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0012 - val_loss: 1.7439e-04\n",
      "Epoch 90/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0011 - val_loss: 1.7375e-04\n",
      "Epoch 91/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0011 - val_loss: 3.5472e-04\n",
      "Epoch 92/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0012 - val_loss: 3.6973e-04\n",
      "Epoch 93/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0014 - val_loss: 4.1013e-04\n",
      "Epoch 94/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0012 - val_loss: 2.9150e-04\n",
      "Epoch 95/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0011 - val_loss: 3.6172e-04\n",
      "Epoch 96/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0012 - val_loss: 2.3672e-04\n",
      "Epoch 97/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0011 - val_loss: 2.4157e-04\n",
      "Epoch 98/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 99/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0013 - val_loss: 2.5249e-04\n",
      "Epoch 100/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0013 - val_loss: 3.9725e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train_scaled, epochs=100, batch_size=32, validation_split=0.2, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589baada-df35-4060-badc-638702b6952d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predictions = scaler_y.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f32349-d821-489b-ad08-1021d4ca8885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 3.88, Predicted: 3.7857725620269775\n",
      "Actual: 8.689, Predicted: 8.243406295776367\n",
      "Actual: 13.622, Predicted: 13.289313316345215\n",
      "Actual: 2.335, Predicted: 2.3843777179718018\n",
      "Actual: 5.952999999999999, Predicted: 5.8288893699646\n",
      "Actual: 4.869, Predicted: 4.867486953735352\n",
      "Actual: 14.768, Predicted: 14.285703659057617\n",
      "Actual: 7.423999999999999, Predicted: 7.027111053466797\n",
      "Actual: 4.103, Predicted: 4.018638610839844\n",
      "Actual: 4.519, Predicted: 4.443005084991455\n",
      "Actual: 14.021, Predicted: 13.749194145202637\n",
      "Actual: 14.034, Predicted: 13.50745964050293\n",
      "Actual: 4.85, Predicted: 4.809767246246338\n",
      "Actual: 9.453, Predicted: 9.00403118133545\n",
      "Actual: 6.222, Predicted: 5.966836929321289\n",
      "Actual: 14.445, Predicted: 14.094795227050781\n",
      "Actual: 11.062, Predicted: 10.827873229980469\n",
      "Actual: 2.455, Predicted: 2.234165906906128\n",
      "Actual: 6.273, Predicted: 6.081531524658203\n",
      "Actual: 4.303, Predicted: 4.237070083618164\n",
      "Actual: 5.066, Predicted: 5.376184463500977\n",
      "Actual: 10.941999999999998, Predicted: 10.562553405761719\n",
      "Actual: 4.859, Predicted: 4.741406440734863\n",
      "Actual: 3.629, Predicted: 3.548335552215576\n",
      "Actual: 4.924, Predicted: 4.917017936706543\n",
      "Actual: 12.048, Predicted: 11.655854225158691\n",
      "Actual: 13.157, Predicted: 12.885157585144043\n",
      "Actual: 10.944, Predicted: 10.727553367614746\n",
      "Actual: 9.264, Predicted: 9.066490173339844\n",
      "Actual: 8.498999999999999, Predicted: 8.416727066040039\n",
      "Actual: 5.902, Predicted: 5.567364692687988\n",
      "Actual: 13.775, Predicted: 13.490724563598633\n",
      "Actual: 2.488, Predicted: 2.5071864128112793\n",
      "Actual: 3.628, Predicted: 3.489253282546997\n",
      "Actual: 14.201, Predicted: 13.805991172790527\n",
      "Actual: 13.22, Predicted: 12.935356140136719\n",
      "Actual: 5.186, Predicted: 6.062929630279541\n",
      "Actual: 9.338, Predicted: 8.877964973449707\n",
      "Actual: 3.422, Predicted: 3.453376531600952\n",
      "Actual: 5.118, Predicted: 4.988079071044922\n",
      "Actual: 13.687, Predicted: 13.470815658569336\n",
      "Actual: 3.069, Predicted: 2.9704506397247314\n",
      "Actual: 12.324000000000002, Predicted: 12.171703338623047\n",
      "Actual: 13.807, Predicted: 13.399413108825684\n",
      "Actual: 1.836, Predicted: 1.5650696754455566\n",
      "Actual: 5.702000000000001, Predicted: 5.652926921844482\n",
      "Actual: 13.401, Predicted: 13.481656074523926\n",
      "Actual: 11.892, Predicted: 11.856433868408203\n",
      "Actual: 12.984000000000002, Predicted: 12.739315032958984\n",
      "Actual: 8.542, Predicted: 8.066984176635742\n",
      "Actual: 5.031000000000001, Predicted: 4.9800944328308105\n",
      "Actual: 11.514, Predicted: 11.767451286315918\n",
      "Actual: 4.8660000000000005, Predicted: 5.004668235778809\n",
      "Actual: 12.095999999999998, Predicted: 11.9633207321167\n",
      "Actual: 14.285, Predicted: 13.738141059875488\n",
      "Actual: 3.2430000000000003, Predicted: 3.3023922443389893\n",
      "Actual: 9.735, Predicted: 9.160901069641113\n",
      "Actual: 8.511000000000001, Predicted: 8.23102855682373\n",
      "Actual: 12.856, Predicted: 12.70763874053955\n",
      "Actual: 14.144, Predicted: 13.819437980651855\n",
      "Actual: 3.656, Predicted: 3.6892712116241455\n",
      "Actual: 13.164, Predicted: 13.163073539733887\n",
      "Actual: 12.093, Predicted: 12.05123519897461\n",
      "Actual: 2.781, Predicted: 2.673861503601074\n",
      "Actual: 11.831, Predicted: 11.637002944946289\n",
      "Actual: 13.405, Predicted: 12.810302734375\n",
      "Actual: 13.752, Predicted: 13.443079948425293\n",
      "Actual: 14.052, Predicted: 13.775991439819336\n",
      "Actual: 9.488, Predicted: 8.958218574523926\n",
      "Actual: 4.8260000000000005, Predicted: 4.751341342926025\n",
      "Actual: 13.807, Predicted: 13.445301055908203\n",
      "Actual: 5.89, Predicted: 5.7295331954956055\n",
      "Actual: 4.959, Predicted: 4.966492176055908\n",
      "Actual: 14.392, Predicted: 14.1483154296875\n",
      "Actual: 8.25, Predicted: 7.377648830413818\n",
      "Actual: 14.742, Predicted: 14.163646697998047\n",
      "Actual: 8.443999999999999, Predicted: 7.591499328613281\n",
      "Actual: 3.1950000000000003, Predicted: 3.3147716522216797\n",
      "Actual: 11.604, Predicted: 11.280165672302246\n",
      "Actual: 13.105, Predicted: 12.856799125671387\n",
      "Actual: 13.412, Predicted: 13.086149215698242\n",
      "Actual: 7.9209999999999985, Predicted: 7.710668563842773\n",
      "Actual: 2.052, Predicted: 2.2625577449798584\n",
      "Actual: 3.5980000000000003, Predicted: 3.668630838394165\n",
      "Actual: 14.138, Predicted: 13.786555290222168\n",
      "Actual: 14.375, Predicted: 14.10662841796875\n",
      "Actual: 9.552, Predicted: 9.148456573486328\n",
      "Actual: 4.134, Predicted: 4.003612041473389\n",
      "Actual: 11.155, Predicted: 10.983360290527344\n",
      "Actual: 9.729, Predicted: 9.52989387512207\n",
      "Actual: 3.306, Predicted: 3.3366713523864746\n",
      "Actual: 14.140999999999998, Predicted: 13.688804626464844\n",
      "Actual: 14.377, Predicted: 13.93565559387207\n",
      "Actual: 13.796, Predicted: 13.467939376831055\n",
      "Actual: 9.671, Predicted: 9.335206985473633\n",
      "Actual: 7.329999999999999, Predicted: 7.273313522338867\n",
      "Actual: 6.404, Predicted: 6.186159610748291\n",
      "Actual: 1.793, Predicted: 2.108931303024292\n",
      "Actual: 10.787999999999998, Predicted: 10.826735496520996\n",
      "Actual: 14.630999999999998, Predicted: 14.08641242980957\n",
      "Actual: 14.188, Predicted: 13.807901382446289\n",
      "Actual: 7.738999999999999, Predicted: 7.529344081878662\n",
      "Actual: 2.228, Predicted: 3.226255178451538\n",
      "Actual: 8.280999999999999, Predicted: 8.126952171325684\n",
      "Actual: 11.984000000000002, Predicted: 11.740989685058594\n",
      "Actual: 3.458, Predicted: 3.5687644481658936\n",
      "Actual: 6.295, Predicted: 6.052702903747559\n",
      "Actual: 2.291, Predicted: 2.130901575088501\n",
      "Actual: 9.006, Predicted: 8.364973068237305\n",
      "Actual: 13.351, Predicted: 13.135810852050781\n",
      "Actual: 14.144, Predicted: 13.633696556091309\n",
      "Actual: 14.37, Predicted: 13.865548133850098\n",
      "Actual: 6.377999999999999, Predicted: 6.064322471618652\n",
      "Actual: 9.584, Predicted: 9.274450302124023\n",
      "Actual: 14.255999999999998, Predicted: 13.92967414855957\n",
      "Actual: 1.966, Predicted: 2.352968692779541\n",
      "Actual: 13.514, Predicted: 13.203841209411621\n",
      "Actual: 4.259, Predicted: 4.220756530761719\n",
      "Actual: 2.713, Predicted: 2.7878737449645996\n",
      "Actual: 12.153, Predicted: 11.847051620483398\n",
      "Actual: 9.281, Predicted: 9.085572242736816\n",
      "Actual: 11.763, Predicted: 11.963839530944824\n",
      "Actual: 4.016, Predicted: 3.965308904647827\n",
      "Actual: 14.505, Predicted: 14.04671573638916\n",
      "Actual: 3.604, Predicted: 3.392691135406494\n",
      "Actual: 3.921, Predicted: 3.9629199504852295\n",
      "Actual: 3.196, Predicted: 3.131192207336426\n",
      "Actual: 2.172, Predicted: 2.048346519470215\n",
      "Actual: 9.516, Predicted: 9.208765983581543\n",
      "Actual: 14.231, Predicted: 13.824633598327637\n",
      "Actual: 11.685, Predicted: 11.505175590515137\n",
      "Actual: 11.354, Predicted: 11.229473114013672\n",
      "Actual: 3.071, Predicted: 3.0382652282714844\n",
      "Actual: 14.798, Predicted: 14.23005199432373\n",
      "Actual: 12.872, Predicted: 12.631389617919922\n",
      "Actual: 11.097, Predicted: 10.962600708007812\n",
      "Actual: 5.077, Predicted: 5.141430854797363\n",
      "Actual: 5.809, Predicted: 5.063961982727051\n",
      "Actual: 8.722000000000001, Predicted: 8.456966400146484\n",
      "Actual: 8.991999999999997, Predicted: 8.701128959655762\n",
      "Actual: 7.1560000000000015, Predicted: 6.790794849395752\n",
      "Actual: 3.832, Predicted: 3.79581618309021\n",
      "Actual: 3.155, Predicted: 2.9604692459106445\n",
      "Actual: 3.3360000000000003, Predicted: 3.252474784851074\n",
      "Actual: 11.845, Predicted: 11.551983833312988\n",
      "Actual: 14.429, Predicted: 13.944520950317383\n",
      "Actual: 2.077, Predicted: 1.942907452583313\n",
      "Actual: 3.5, Predicted: 3.6198151111602783\n",
      "Actual: 11.729, Predicted: 11.590461730957031\n",
      "Actual: 3.092, Predicted: 3.186190366744995\n",
      "Actual: 6.3, Predicted: 6.11014986038208\n",
      "Actual: 13.395, Predicted: 12.946611404418945\n",
      "Actual: 7.486999999999999, Predicted: 7.722088813781738\n",
      "Actual: 3.24, Predicted: 3.4825046062469482\n",
      "Actual: 13.23, Predicted: 12.899738311767578\n",
      "Actual: 14.298, Predicted: 13.841878890991211\n",
      "Actual: 1.003, Predicted: 0.9039235711097717\n",
      "Actual: 2.7060000000000004, Predicted: 3.312258005142212\n",
      "Actual: 2.466, Predicted: 2.461951732635498\n",
      "Actual: 2.611, Predicted: 2.3915603160858154\n",
      "Actual: 4.622, Predicted: 4.486752986907959\n",
      "Actual: 4.94, Predicted: 4.993185997009277\n",
      "Actual: 13.537, Predicted: 12.753643035888672\n",
      "Actual: 4.811, Predicted: 4.745944976806641\n",
      "Actual: 2.286, Predicted: 2.1100590229034424\n",
      "Actual: 3.8630000000000004, Predicted: 3.8639719486236572\n",
      "Actual: 13.347, Predicted: 12.985434532165527\n",
      "Actual: 9.077, Predicted: 8.761740684509277\n",
      "Actual: 9.157, Predicted: 8.837889671325684\n",
      "Actual: 9.67, Predicted: 9.25461483001709\n",
      "Actual: 3.5, Predicted: 3.396902561187744\n",
      "Actual: 11.759, Predicted: 11.456363677978516\n",
      "Actual: 13.505999999999998, Predicted: 13.36784839630127\n",
      "Actual: 11.386, Predicted: 11.603719711303711\n",
      "Actual: 14.122, Predicted: 13.86375904083252\n",
      "Actual: 14.408, Predicted: 13.93524169921875\n",
      "Actual: 11.743, Predicted: 11.547213554382324\n",
      "Actual: 11.235, Predicted: 11.250617980957031\n",
      "Actual: 11.284999999999998, Predicted: 11.131547927856445\n",
      "Actual: 4.059, Predicted: 3.9790830612182617\n",
      "Actual: 5.399, Predicted: 5.222238063812256\n",
      "Actual: 6.205, Predicted: 6.005527973175049\n",
      "Actual: 6.74, Predicted: 6.3802666664123535\n",
      "Actual: 7.748999999999999, Predicted: 7.676156997680664\n",
      "Actual: 3.513, Predicted: 3.477527618408203\n",
      "Actual: 10.69, Predicted: 10.592105865478516\n",
      "Actual: 13.331, Predicted: 13.019640922546387\n",
      "Actual: 5.097, Predicted: 5.147637844085693\n",
      "Actual: 13.713, Predicted: 13.371332168579102\n",
      "Actual: 1.941, Predicted: 1.8324496746063232\n",
      "Actual: 4.9190000000000005, Predicted: 4.972251892089844\n",
      "Actual: 13.557, Predicted: 13.148906707763672\n",
      "Actual: 2.71, Predicted: 2.6866250038146973\n",
      "Actual: 4.327999999999999, Predicted: 4.254374027252197\n",
      "Actual: 9.056, Predicted: 8.746722221374512\n",
      "Actual: 2.857, Predicted: 2.911397933959961\n",
      "Actual: 5.272, Predicted: 5.469737529754639\n",
      "Actual: 4.6850000000000005, Predicted: 4.490819931030273\n",
      "Actual: 6.397, Predicted: 6.165314674377441\n",
      "Actual: 7.185999999999999, Predicted: 7.060833930969238\n",
      "Actual: 13.484000000000002, Predicted: 13.542919158935547\n",
      "Actual: 14.223, Predicted: 13.82289981842041\n",
      "Actual: 10.611, Predicted: 10.485796928405762\n",
      "Actual: 9.627, Predicted: 9.320263862609863\n",
      "Actual: 3.14, Predicted: 3.720808267593384\n",
      "Actual: 14.238, Predicted: 13.61009693145752\n",
      "Actual: 8.58, Predicted: 8.203561782836914\n",
      "Actual: 11.222, Predicted: 11.088445663452148\n",
      "Actual: 11.797, Predicted: 11.64931583404541\n",
      "Actual: 13.964, Predicted: 13.750123023986816\n",
      "Actual: 3.4560000000000004, Predicted: 3.4120030403137207\n",
      "Actual: 14.468, Predicted: 14.277161598205566\n",
      "Actual: 7.767999999999998, Predicted: 7.8977766036987305\n",
      "Actual: 8.838, Predicted: 8.408882141113281\n",
      "Actual: 6.047999999999999, Predicted: 5.87472677230835\n",
      "Actual: 11.925, Predicted: 11.719101905822754\n",
      "Actual: 10.898, Predicted: 10.4508695602417\n",
      "Actual: 14.242, Predicted: 13.733206748962402\n",
      "Actual: 13.161, Predicted: 12.924757957458496\n",
      "Actual: 3.104, Predicted: 3.011092185974121\n",
      "Actual: 5.596, Predicted: 5.361490726470947\n",
      "Actual: 13.308, Predicted: 13.059828758239746\n",
      "Actual: 10.851, Predicted: 10.33548355102539\n",
      "Actual: 8.594999999999999, Predicted: 8.324699401855469\n",
      "Actual: 5.245, Predicted: 5.327959060668945\n",
      "Actual: 7.487, Predicted: 7.024861812591553\n",
      "Actual: 11.308, Predicted: 11.241230010986328\n",
      "Actual: 5.915, Predicted: 5.719291687011719\n",
      "Actual: 13.204, Predicted: 12.910974502563477\n",
      "Actual: 6.377999999999999, Predicted: 6.0747389793396\n",
      "Actual: 9.55, Predicted: 9.04859447479248\n",
      "Actual: 6.356, Predicted: 6.083885669708252\n",
      "Actual: 3.333, Predicted: 3.1883723735809326\n",
      "Actual: 8.870999999999997, Predicted: 8.545065879821777\n",
      "Actual: 2.616, Predicted: 2.4306015968322754\n",
      "Actual: 3.3960000000000004, Predicted: 3.356992721557617\n",
      "Actual: 2.989, Predicted: 2.6952850818634033\n",
      "Actual: 3.33, Predicted: 3.357536792755127\n",
      "Actual: 12.127999999999998, Predicted: 12.007071495056152\n",
      "Actual: 9.196, Predicted: 8.848255157470703\n",
      "Actual: 13.217, Predicted: 13.494153022766113\n",
      "Actual: 14.339, Predicted: 13.923277854919434\n",
      "Actual: 14.274, Predicted: 13.827306747436523\n",
      "Actual: 4.6, Predicted: 4.5153303146362305\n",
      "Actual: 7.6839999999999975, Predicted: 7.581937313079834\n",
      "Actual: 9.021, Predicted: 8.77678108215332\n",
      "Actual: 13.531, Predicted: 13.279333114624023\n",
      "Actual: 13.577, Predicted: 13.206890106201172\n",
      "Actual: 3.005, Predicted: 3.0641531944274902\n",
      "Actual: 15.212999999999997, Predicted: 14.667611122131348\n",
      "Actual: 12.146, Predicted: 11.920660972595215\n",
      "Actual: 7.617999999999999, Predicted: 7.588298320770264\n",
      "Actual: 14.827, Predicted: 14.265138626098633\n",
      "Actual: 11.989999999999998, Predicted: 11.818534851074219\n",
      "Actual: 13.365, Predicted: 13.239603042602539\n",
      "Actual: 10.803, Predicted: 10.756213188171387\n",
      "Actual: 11.239, Predicted: 10.981803894042969\n",
      "Actual: 3.559, Predicted: 3.598627805709839\n",
      "Actual: 14.019, Predicted: 13.228068351745605\n",
      "Actual: 13.824000000000002, Predicted: 13.382540702819824\n",
      "Actual: 11.478, Predicted: 11.623735427856445\n",
      "Actual: 2.0540000000000003, Predicted: 1.9626495838165283\n",
      "Actual: 7.906999999999999, Predicted: 7.796426296234131\n",
      "Actual: 5.01, Predicted: 4.994927883148193\n",
      "Actual: 8.442, Predicted: 8.305819511413574\n",
      "Actual: 13.294, Predicted: 13.198394775390625\n",
      "Actual: 4.152, Predicted: 3.5267908573150635\n",
      "Actual: 8.69, Predicted: 8.285687446594238\n",
      "Actual: 2.627, Predicted: 2.748281717300415\n",
      "Actual: 9.378, Predicted: 8.853524208068848\n",
      "Actual: 13.77, Predicted: 13.753698348999023\n",
      "Actual: 4.222, Predicted: 4.084741592407227\n",
      "Actual: 14.226, Predicted: 13.71044635772705\n",
      "Actual: 9.12, Predicted: 8.712080001831055\n",
      "Actual: 3.069, Predicted: 2.563718795776367\n",
      "Actual: 4.257, Predicted: 4.213856220245361\n",
      "Actual: 4.538, Predicted: 5.123318672180176\n",
      "Actual: 6.738, Predicted: 6.421356201171875\n",
      "Actual: 3.743, Predicted: 3.570183277130127\n",
      "Actual: 14.06, Predicted: 13.621952056884766\n",
      "Actual: 15.160999999999998, Predicted: 14.589075088500977\n",
      "Actual: 11.977, Predicted: 11.639676094055176\n",
      "Actual: 3.457, Predicted: 3.154308795928955\n",
      "Actual: 4.31, Predicted: 4.308543682098389\n",
      "Actual: 13.113, Predicted: 12.774065017700195\n",
      "Actual: 2.226, Predicted: 3.159837484359741\n",
      "Actual: 13.765, Predicted: 13.435011863708496\n",
      "Actual: 2.376, Predicted: 2.421565294265747\n",
      "Actual: 7.994, Predicted: 7.666554927825928\n",
      "Actual: 3.039, Predicted: 2.9032645225524902\n",
      "Actual: 14.145, Predicted: 13.648240089416504\n",
      "Actual: 11.771999999999998, Predicted: 11.505160331726074\n",
      "Actual: 14.351, Predicted: 13.804521560668945\n",
      "Actual: 8.535, Predicted: 7.093274116516113\n",
      "Actual: 5.731, Predicted: 5.553919315338135\n",
      "Actual: 12.039, Predicted: 11.794544219970703\n",
      "Actual: 2.506, Predicted: 2.491586208343506\n",
      "Actual: 8.247, Predicted: 8.137521743774414\n",
      "Actual: 10.53, Predicted: 10.83279800415039\n",
      "Actual: 3.687, Predicted: 3.5079262256622314\n",
      "Actual: 3.766, Predicted: 3.629055976867676\n",
      "Actual: 3.7780000000000005, Predicted: 3.8497798442840576\n",
      "Actual: 13.932, Predicted: 13.709033012390137\n",
      "Actual: 8.366, Predicted: 8.170297622680664\n",
      "Actual: 3.8220000000000005, Predicted: 3.8098013401031494\n",
      "Actual: 5.973, Predicted: 5.6831231117248535\n",
      "Actual: 14.512, Predicted: 14.385981559753418\n",
      "Actual: 5.247000000000001, Predicted: 5.249709129333496\n",
      "Actual: 11.338, Predicted: 11.131092071533203\n",
      "Actual: 3.74, Predicted: 3.7675867080688477\n",
      "Actual: 5.827999999999999, Predicted: 5.717881679534912\n",
      "Actual: 3.39, Predicted: 3.4598207473754883\n",
      "Actual: 2.862, Predicted: 2.8653438091278076\n",
      "Actual: 13.297, Predicted: 12.908096313476562\n",
      "Actual: 2.9560000000000004, Predicted: 3.0663530826568604\n",
      "Actual: 8.892000000000001, Predicted: 8.690567016601562\n",
      "Actual: 14.742, Predicted: 14.276848793029785\n",
      "Actual: 11.71, Predicted: 12.153430938720703\n",
      "Actual: 11.861999999999998, Predicted: 11.531238555908203\n",
      "Actual: 1.551, Predicted: 1.2233988046646118\n",
      "Actual: 7.635999999999999, Predicted: 7.483482360839844\n",
      "Actual: 13.698, Predicted: 13.44638442993164\n",
      "Actual: 13.678, Predicted: 13.299519538879395\n",
      "Actual: 13.153, Predicted: 12.64907455444336\n",
      "Actual: 13.691, Predicted: 13.53695297241211\n",
      "Actual: 2.402, Predicted: 2.113909959793091\n",
      "Actual: 12.199000000000002, Predicted: 12.021855354309082\n",
      "Actual: 4.506, Predicted: 4.540576457977295\n",
      "Actual: 13.298, Predicted: 12.819872856140137\n",
      "Actual: 14.231, Predicted: 13.841270446777344\n",
      "Actual: 8.738, Predicted: 8.541167259216309\n",
      "Actual: 8.679, Predicted: 8.229324340820312\n",
      "Actual: 4.038, Predicted: 3.9926276206970215\n",
      "Actual: 14.09, Predicted: 13.621697425842285\n",
      "Actual: 13.214, Predicted: 12.964624404907227\n",
      "Actual: 3.898, Predicted: 3.785440683364868\n",
      "Actual: 13.488, Predicted: 13.221420288085938\n",
      "Actual: 2.008, Predicted: 2.1306545734405518\n",
      "Actual: 9.367, Predicted: 8.855990409851074\n",
      "Actual: 5.671, Predicted: 5.293556213378906\n",
      "Actual: 8.865, Predicted: 8.611552238464355\n",
      "Actual: 13.442, Predicted: 13.277239799499512\n",
      "Actual: 9.232, Predicted: 8.900347709655762\n",
      "Actual: 11.954, Predicted: 11.768272399902344\n",
      "Actual: 12.406, Predicted: 12.049702644348145\n",
      "Actual: 8.173, Predicted: 7.916633605957031\n",
      "Actual: 11.946, Predicted: 11.68930435180664\n",
      "Actual: 13.434, Predicted: 13.048955917358398\n",
      "Actual: 4.9990000000000006, Predicted: 5.244172096252441\n",
      "Actual: 6.814, Predicted: 6.475107192993164\n",
      "Actual: 5.4510000000000005, Predicted: 5.4470038414001465\n",
      "Actual: 7.76, Predicted: 7.5125346183776855\n",
      "Actual: 5.318, Predicted: 5.267568111419678\n",
      "Actual: 8.445, Predicted: 8.581656455993652\n",
      "Actual: 14.139, Predicted: 13.726115226745605\n",
      "Actual: 2.609, Predicted: 2.6745991706848145\n",
      "Actual: 6.183, Predicted: 6.118374347686768\n",
      "Actual: 14.31, Predicted: 13.972525596618652\n",
      "Actual: 14.151, Predicted: 14.154906272888184\n",
      "Actual: 3.491, Predicted: 3.4521093368530273\n",
      "Actual: 4.421, Predicted: 4.348766326904297\n",
      "Actual: 13.836, Predicted: 13.559253692626953\n",
      "Actual: 9.238, Predicted: 8.886655807495117\n",
      "Actual: 5.952000000000001, Predicted: 5.767088413238525\n",
      "Actual: 5.093, Predicted: 5.247509002685547\n",
      "Actual: 13.223, Predicted: 12.936922073364258\n",
      "Actual: 4.922, Predicted: 4.48244047164917\n",
      "Actual: 7.561999999999998, Predicted: 7.396266460418701\n",
      "Actual: 11.62, Predicted: 11.37350082397461\n",
      "Actual: 13.547, Predicted: 13.180444717407227\n",
      "Actual: 12.03, Predicted: 11.748745918273926\n",
      "Actual: 14.004, Predicted: 13.719063758850098\n",
      "Actual: 4.704, Predicted: 4.594546794891357\n",
      "Actual: 4.026, Predicted: 3.883941411972046\n",
      "Actual: 8.588999999999999, Predicted: 8.502406120300293\n",
      "Actual: 2.905, Predicted: 2.913036823272705\n",
      "Actual: 14.349, Predicted: 13.974316596984863\n",
      "Actual: 8.434, Predicted: 8.434076309204102\n",
      "Actual: 13.296, Predicted: 12.946310043334961\n",
      "Actual: 3.265, Predicted: 3.196038246154785\n",
      "Actual: 14.059, Predicted: 13.658308029174805\n",
      "Actual: 11.665, Predicted: 11.29110050201416\n",
      "Actual: 11.867, Predicted: 11.859929084777832\n",
      "Actual: 13.475, Predicted: 13.161251068115234\n",
      "Actual: 8.097999999999999, Predicted: 7.998164653778076\n",
      "Actual: 13.789, Predicted: 13.59514331817627\n",
      "Actual: 2.492, Predicted: 2.7184414863586426\n",
      "Actual: 3.7850000000000006, Predicted: 3.8165197372436523\n",
      "Actual: 13.896, Predicted: 13.611762046813965\n",
      "Actual: 5.405, Predicted: 5.337618827819824\n",
      "Actual: 13.478, Predicted: 13.18464183807373\n",
      "Actual: 2.9410000000000003, Predicted: 3.0558059215545654\n",
      "Actual: 2.6790000000000003, Predicted: 2.7746741771698\n",
      "Actual: 5.524, Predicted: 5.386488914489746\n",
      "Actual: 13.769, Predicted: 13.524834632873535\n",
      "Actual: 9.096, Predicted: 8.685484886169434\n",
      "Actual: 2.71, Predicted: 2.707346200942993\n",
      "Actual: 12.03, Predicted: 11.658563613891602\n",
      "Actual: 2.082, Predicted: 1.961768388748169\n"
     ]
    }
   ],
   "source": [
    "# Compare predictions with actual values\n",
    "actual = scaler_y.inverse_transform(y_test_scaled)\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"Actual: {actual[i][0]}, Predicted: {predictions[i][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13167292-bb8c-4f58-83c6-985362224888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.24827897800239998\n",
      "Mean Squared Error (MSE): 0.09677026520194304\n",
      "Root Mean Squared Error (RMSE): 0.31107919442152193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(actual, predictions)\n",
    "mse = mean_squared_error(actual, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
