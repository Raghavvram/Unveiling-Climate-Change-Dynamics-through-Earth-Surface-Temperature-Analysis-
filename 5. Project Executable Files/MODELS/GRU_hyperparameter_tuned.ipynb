{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d3c21f-bb02-4f3f-ac53-41ebfa77843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, Input\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eae8a5d-e99f-4357-8160-37b391c650d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV file\n",
    "file_path = 'GlobalTemperatures.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Impute LandAverageTemperature and LandAverageTemperatureUncertainty with mean\n",
    "df['LandAverageTemperature'].fillna(df['LandAverageTemperature'].mean(), inplace=True)\n",
    "df['LandAverageTemperatureUncertainty'].fillna(df['LandAverageTemperatureUncertainty'].mean(), inplace=True)\n",
    "\n",
    "# For columns with 1200 missing values, drop those rows\n",
    "cols_to_dropna = ['LandMaxTemperature', 'LandMaxTemperatureUncertainty', 'LandMinTemperature', 'LandMinTemperatureUncertainty', 'LandAndOceanAverageTemperature', 'LandAndOceanAverageTemperatureUncertainty']\n",
    "df.dropna(subset=cols_to_dropna, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2db283bf-dc44-4aef-a6f9-f9cd3592b89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1593, 9, 1)\n",
      "X_test_scaled shape: (399, 9, 1)\n",
      "y_train_scaled shape: (1593, 1)\n",
      "y_test_scaled shape: (399, 1)\n"
     ]
    }
   ],
   "source": [
    "# Add Year and Month columns based on 'dt' column\n",
    "df['Year'] = pd.to_datetime(df['dt']).dt.year\n",
    "df['Month'] = pd.to_datetime(df['dt']).dt.month\n",
    "\n",
    "# Prepare X (features) and y (target)\n",
    "X = df.drop(['LandAverageTemperature', 'dt'], axis=1)\n",
    "y = df['LandAverageTemperature']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale X and y using MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler_x.fit_transform(X_train)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "# Only transform the testing data\n",
    "X_test_scaled = scaler_x.transform(X_test)\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Reshape X_train_scaled and X_test_scaled for RNN input\n",
    "X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"X_test_scaled shape:\", X_test_scaled.shape)\n",
    "print(\"y_train_scaled shape:\", y_train_scaled.shape)\n",
    "print(\"y_test_scaled shape:\", y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3177c5d-8009-4cb7-9b97-246797ce5b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END .........dropout_rate=0.1, optimizer=adam, units=50; total time=   3.1s\n",
      "[CV] END .........dropout_rate=0.1, optimizer=adam, units=50; total time=   3.3s\n",
      "[CV] END .........dropout_rate=0.1, optimizer=adam, units=50; total time=   3.3s\n",
      "[CV] END ........dropout_rate=0.1, optimizer=adam, units=100; total time=   3.2s\n",
      "[CV] END ........dropout_rate=0.1, optimizer=adam, units=100; total time=   3.3s\n",
      "[CV] END ........dropout_rate=0.1, optimizer=adam, units=100; total time=   3.2s\n",
      "[CV] END ........dropout_rate=0.2, optimizer=adam, units=150; total time=   3.4s\n",
      "[CV] END ........dropout_rate=0.2, optimizer=adam, units=150; total time=   3.2s\n",
      "[CV] END ........dropout_rate=0.2, optimizer=adam, units=150; total time=   3.3s\n",
      "[CV] END .....dropout_rate=0.1, optimizer=rmsprop, units=150; total time=   3.3s\n",
      "[CV] END .....dropout_rate=0.1, optimizer=rmsprop, units=150; total time=   3.5s\n",
      "[CV] END .....dropout_rate=0.1, optimizer=rmsprop, units=150; total time=   3.2s\n",
      "[CV] END ......dropout_rate=0.1, optimizer=rmsprop, units=50; total time=   3.0s\n",
      "[CV] END ......dropout_rate=0.1, optimizer=rmsprop, units=50; total time=   3.0s\n",
      "[CV] END ......dropout_rate=0.1, optimizer=rmsprop, units=50; total time=   3.4s\n",
      "[CV] END ........dropout_rate=0.3, optimizer=adam, units=100; total time=   3.1s\n",
      "[CV] END ........dropout_rate=0.3, optimizer=adam, units=100; total time=   3.1s\n",
      "[CV] END ........dropout_rate=0.3, optimizer=adam, units=100; total time=   3.1s\n",
      "[CV] END .....dropout_rate=0.3, optimizer=rmsprop, units=100; total time=   3.1s\n",
      "[CV] END .....dropout_rate=0.3, optimizer=rmsprop, units=100; total time=   3.5s\n",
      "[CV] END .....dropout_rate=0.3, optimizer=rmsprop, units=100; total time=   3.1s\n",
      "[CV] END ......dropout_rate=0.3, optimizer=rmsprop, units=50; total time=   3.0s\n",
      "[CV] END ......dropout_rate=0.3, optimizer=rmsprop, units=50; total time=   3.0s\n",
      "[CV] END ......dropout_rate=0.3, optimizer=rmsprop, units=50; total time=   3.1s\n",
      "[CV] END .....dropout_rate=0.2, optimizer=rmsprop, units=150; total time=   4.0s\n",
      "[CV] END .....dropout_rate=0.2, optimizer=rmsprop, units=150; total time=   3.2s\n",
      "[CV] END .....dropout_rate=0.2, optimizer=rmsprop, units=150; total time=   3.2s\n",
      "[CV] END ........dropout_rate=0.1, optimizer=adam, units=150; total time=   3.3s\n",
      "[CV] END ........dropout_rate=0.1, optimizer=adam, units=150; total time=   3.4s\n",
      "[CV] END ........dropout_rate=0.1, optimizer=adam, units=150; total time=   3.5s\n",
      "Best parameters found:  {'units': 150, 'optimizer': 'adam', 'dropout_rate': 0.1}\n",
      "Best CV score:  0.4762809263816325\n",
      "Test loss:  0.542034034924072\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, Input\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to create the GRU model\n",
    "def create_gru_model(optimizer='adam', dropout_rate=0.2, units=100):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "    model.add(GRU(units, activation='relu', return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(GRU(units, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model\n",
    "\n",
    "# Wrap the Keras model so it can be used by sklearn\n",
    "model = KerasRegressor(build_fn=create_gru_model, verbose=0,units=50,dropout_rate=0.1)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.1, 0.2, 0.3],\n",
    "    'units': [50, 100, 150]\n",
    "}\n",
    "\n",
    "# Setup random search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                                   n_iter=10, cv=3, verbose=2, random_state=42)\n",
    "\n",
    "# Perform the random search\n",
    "random_search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best CV score: \", random_search.best_score_)\n",
    "\n",
    "# Use the best model found\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on test data if available\n",
    "test_loss = best_model.score(X_test_scaled, y_test_scaled)\n",
    "print(\"Test loss: \", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca70bef7-b0eb-43fa-bdcb-abd430e6a1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 - 4s - 90ms/step - loss: 0.1238 - val_loss: 0.0542\n",
      "Epoch 2/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0412 - val_loss: 0.0221\n",
      "Epoch 3/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0169 - val_loss: 0.0096\n",
      "Epoch 4/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0161 - val_loss: 0.0109\n",
      "Epoch 5/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0143 - val_loss: 0.0078\n",
      "Epoch 6/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0127 - val_loss: 0.0071\n",
      "Epoch 7/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 8/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0117 - val_loss: 0.0063\n",
      "Epoch 9/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0104 - val_loss: 0.0051\n",
      "Epoch 10/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 11/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0087 - val_loss: 0.0037\n",
      "Epoch 12/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0076 - val_loss: 0.0032\n",
      "Epoch 13/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0079 - val_loss: 0.0034\n",
      "Epoch 14/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0066 - val_loss: 0.0033\n",
      "Epoch 15/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0061 - val_loss: 0.0023\n",
      "Epoch 16/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 17/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0058 - val_loss: 0.0016\n",
      "Epoch 18/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0051 - val_loss: 0.0018\n",
      "Epoch 19/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0056 - val_loss: 0.0020\n",
      "Epoch 20/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 21/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0047 - val_loss: 0.0016\n",
      "Epoch 22/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 23/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0044 - val_loss: 0.0013\n",
      "Epoch 24/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 25/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 26/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 27/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 28/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 29/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 30/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0042 - val_loss: 0.0014\n",
      "Epoch 31/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 32/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 33/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0037 - val_loss: 9.1696e-04\n",
      "Epoch 34/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0036 - val_loss: 9.9962e-04\n",
      "Epoch 35/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 36/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 37/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0036 - val_loss: 9.1881e-04\n",
      "Epoch 38/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 39/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0036 - val_loss: 9.0897e-04\n",
      "Epoch 40/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 41/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 42/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 44/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 45/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 46/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 47/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0031 - val_loss: 8.9177e-04\n",
      "Epoch 48/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0035 - val_loss: 8.2379e-04\n",
      "Epoch 49/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0033 - val_loss: 9.0983e-04\n",
      "Epoch 50/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0031 - val_loss: 8.3533e-04\n",
      "Epoch 52/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0036 - val_loss: 9.8334e-04\n",
      "Epoch 53/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 54/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 55/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 56/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0027 - val_loss: 8.4861e-04\n",
      "Epoch 57/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 58/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0027 - val_loss: 9.1545e-04\n",
      "Epoch 59/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 60/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0029 - val_loss: 8.3184e-04\n",
      "Epoch 61/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0029 - val_loss: 9.8602e-04\n",
      "Epoch 62/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0027 - val_loss: 8.0065e-04\n",
      "Epoch 63/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0028 - val_loss: 9.8099e-04\n",
      "Epoch 64/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0027 - val_loss: 8.7428e-04\n",
      "Epoch 65/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 66/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0026 - val_loss: 9.1770e-04\n",
      "Epoch 67/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0024 - val_loss: 8.9224e-04\n",
      "Epoch 68/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0026 - val_loss: 8.9606e-04\n",
      "Epoch 69/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0025 - val_loss: 8.5883e-04\n",
      "Epoch 70/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0024 - val_loss: 7.5862e-04\n",
      "Epoch 71/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 72/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0024 - val_loss: 7.5775e-04\n",
      "Epoch 73/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0026 - val_loss: 8.5873e-04\n",
      "Epoch 74/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0024 - val_loss: 7.7057e-04\n",
      "Epoch 75/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0027 - val_loss: 9.1039e-04\n",
      "Epoch 76/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0022 - val_loss: 9.9146e-04\n",
      "Epoch 77/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0023 - val_loss: 8.0940e-04\n",
      "Epoch 78/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0024 - val_loss: 7.6166e-04\n",
      "Epoch 79/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0020 - val_loss: 7.4867e-04\n",
      "Epoch 80/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 81/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0024 - val_loss: 8.7247e-04\n",
      "Epoch 82/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0024 - val_loss: 8.0115e-04\n",
      "Epoch 83/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0023 - val_loss: 7.6489e-04\n",
      "Epoch 84/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0021 - val_loss: 8.1272e-04\n",
      "Epoch 85/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0020 - val_loss: 8.2305e-04\n",
      "Epoch 86/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 87/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0022 - val_loss: 8.7756e-04\n",
      "Epoch 88/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0020 - val_loss: 9.4587e-04\n",
      "Epoch 89/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 90/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0023 - val_loss: 9.8888e-04\n",
      "Epoch 91/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 92/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0022 - val_loss: 6.9794e-04\n",
      "Epoch 93/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 94/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0018 - val_loss: 9.0848e-04\n",
      "Epoch 95/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0019 - val_loss: 7.0658e-04\n",
      "Epoch 96/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 97/100\n",
      "40/40 - 0s - 7ms/step - loss: 0.0021 - val_loss: 7.8228e-04\n",
      "Epoch 98/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0020 - val_loss: 6.6510e-04\n",
      "Epoch 99/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0018 - val_loss: 8.6295e-04\n",
      "Epoch 100/100\n",
      "40/40 - 0s - 6ms/step - loss: 0.0020 - val_loss: 8.0295e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train_scaled, epochs=100, batch_size=32, validation_split=0.2,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "228f1a7e-0580-4d6a-a09c-af109a0cb65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predictions = scaler_y.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5532b73-37c4-4d49-a044-9765c3b40d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 3.88, Predicted: 3.806281805038452\n",
      "Actual: 8.689, Predicted: 8.661441802978516\n",
      "Actual: 13.622, Predicted: 13.519972801208496\n",
      "Actual: 2.335, Predicted: 2.64821195602417\n",
      "Actual: 5.952999999999999, Predicted: 6.254845142364502\n",
      "Actual: 4.869, Predicted: 5.085196495056152\n",
      "Actual: 14.768, Predicted: 14.942634582519531\n",
      "Actual: 7.423999999999999, Predicted: 7.803701400756836\n",
      "Actual: 4.103, Predicted: 3.6517391204833984\n",
      "Actual: 4.519, Predicted: 4.497413158416748\n",
      "Actual: 14.021, Predicted: 13.92534351348877\n",
      "Actual: 14.034, Predicted: 14.0799560546875\n",
      "Actual: 4.85, Predicted: 5.281241416931152\n",
      "Actual: 9.453, Predicted: 9.529918670654297\n",
      "Actual: 6.222, Predicted: 6.207124710083008\n",
      "Actual: 14.445, Predicted: 14.59064769744873\n",
      "Actual: 11.062, Predicted: 11.079059600830078\n",
      "Actual: 2.455, Predicted: 2.5452351570129395\n",
      "Actual: 6.273, Predicted: 6.325991153717041\n",
      "Actual: 4.303, Predicted: 4.232967376708984\n",
      "Actual: 5.066, Predicted: 5.534148216247559\n",
      "Actual: 10.941999999999998, Predicted: 10.881233215332031\n",
      "Actual: 4.859, Predicted: 4.413300037384033\n",
      "Actual: 3.629, Predicted: 3.5561065673828125\n",
      "Actual: 4.924, Predicted: 4.797788143157959\n",
      "Actual: 12.048, Predicted: 12.363597869873047\n",
      "Actual: 13.157, Predicted: 13.36438274383545\n",
      "Actual: 10.944, Predicted: 10.957474708557129\n",
      "Actual: 9.264, Predicted: 9.429533958435059\n",
      "Actual: 8.498999999999999, Predicted: 8.992497444152832\n",
      "Actual: 5.902, Predicted: 5.856821060180664\n",
      "Actual: 13.775, Predicted: 14.008757591247559\n",
      "Actual: 2.488, Predicted: 2.4840433597564697\n",
      "Actual: 3.628, Predicted: 3.902944564819336\n",
      "Actual: 14.201, Predicted: 14.355843544006348\n",
      "Actual: 13.22, Predicted: 13.420527458190918\n",
      "Actual: 5.186, Predicted: 6.547276496887207\n",
      "Actual: 9.338, Predicted: 9.596845626831055\n",
      "Actual: 3.422, Predicted: 3.6295578479766846\n",
      "Actual: 5.118, Predicted: 5.367293357849121\n",
      "Actual: 13.687, Predicted: 13.878990173339844\n",
      "Actual: 3.069, Predicted: 2.764600992202759\n",
      "Actual: 12.324000000000002, Predicted: 12.588973045349121\n",
      "Actual: 13.807, Predicted: 13.974559783935547\n",
      "Actual: 1.836, Predicted: 2.0046348571777344\n",
      "Actual: 5.702000000000001, Predicted: 5.701309680938721\n",
      "Actual: 13.401, Predicted: 14.04561996459961\n",
      "Actual: 11.892, Predicted: 11.892448425292969\n",
      "Actual: 12.984000000000002, Predicted: 12.813446998596191\n",
      "Actual: 8.542, Predicted: 7.643404006958008\n",
      "Actual: 5.031000000000001, Predicted: 5.154860019683838\n",
      "Actual: 11.514, Predicted: 11.25972843170166\n",
      "Actual: 4.8660000000000005, Predicted: 5.2517499923706055\n",
      "Actual: 12.095999999999998, Predicted: 12.503040313720703\n",
      "Actual: 14.285, Predicted: 14.367538452148438\n",
      "Actual: 3.2430000000000003, Predicted: 3.2879059314727783\n",
      "Actual: 9.735, Predicted: 9.720332145690918\n",
      "Actual: 8.511000000000001, Predicted: 8.526711463928223\n",
      "Actual: 12.856, Predicted: 13.024271965026855\n",
      "Actual: 14.144, Predicted: 14.311897277832031\n",
      "Actual: 3.656, Predicted: 3.9045586585998535\n",
      "Actual: 13.164, Predicted: 12.662452697753906\n",
      "Actual: 12.093, Predicted: 12.508281707763672\n",
      "Actual: 2.781, Predicted: 2.8153905868530273\n",
      "Actual: 11.831, Predicted: 12.1276273727417\n",
      "Actual: 13.405, Predicted: 13.39018440246582\n",
      "Actual: 13.752, Predicted: 13.735469818115234\n",
      "Actual: 14.052, Predicted: 14.215584754943848\n",
      "Actual: 9.488, Predicted: 9.562752723693848\n",
      "Actual: 4.8260000000000005, Predicted: 4.869693756103516\n",
      "Actual: 13.807, Predicted: 13.855855941772461\n",
      "Actual: 5.89, Predicted: 6.015948295593262\n",
      "Actual: 4.959, Predicted: 5.217653274536133\n",
      "Actual: 14.392, Predicted: 14.56373119354248\n",
      "Actual: 8.25, Predicted: 7.531846046447754\n",
      "Actual: 14.742, Predicted: 14.63646411895752\n",
      "Actual: 8.443999999999999, Predicted: 10.855435371398926\n",
      "Actual: 3.1950000000000003, Predicted: 3.3037362098693848\n",
      "Actual: 11.604, Predicted: 11.878046989440918\n",
      "Actual: 13.105, Predicted: 13.193679809570312\n",
      "Actual: 13.412, Predicted: 13.573291778564453\n",
      "Actual: 7.9209999999999985, Predicted: 8.217345237731934\n",
      "Actual: 2.052, Predicted: 2.873969554901123\n",
      "Actual: 3.5980000000000003, Predicted: 3.6280934810638428\n",
      "Actual: 14.138, Predicted: 14.272073745727539\n",
      "Actual: 14.375, Predicted: 14.454023361206055\n",
      "Actual: 9.552, Predicted: 9.709832191467285\n",
      "Actual: 4.134, Predicted: 4.033292770385742\n",
      "Actual: 11.155, Predicted: 11.455806732177734\n",
      "Actual: 9.729, Predicted: 9.95715618133545\n",
      "Actual: 3.306, Predicted: 3.2081449031829834\n",
      "Actual: 14.140999999999998, Predicted: 14.157827377319336\n",
      "Actual: 14.377, Predicted: 14.584199905395508\n",
      "Actual: 13.796, Predicted: 14.147163391113281\n",
      "Actual: 9.671, Predicted: 9.858779907226562\n",
      "Actual: 7.329999999999999, Predicted: 7.813701629638672\n",
      "Actual: 6.404, Predicted: 6.71903133392334\n",
      "Actual: 1.793, Predicted: 2.611544132232666\n",
      "Actual: 10.787999999999998, Predicted: 10.770774841308594\n",
      "Actual: 14.630999999999998, Predicted: 14.629107475280762\n",
      "Actual: 14.188, Predicted: 14.451475143432617\n",
      "Actual: 7.738999999999999, Predicted: 7.764157772064209\n",
      "Actual: 2.228, Predicted: 3.8803296089172363\n",
      "Actual: 8.280999999999999, Predicted: 8.435166358947754\n",
      "Actual: 11.984000000000002, Predicted: 12.053311347961426\n",
      "Actual: 3.458, Predicted: 3.3418352603912354\n",
      "Actual: 6.295, Predicted: 6.35084867477417\n",
      "Actual: 2.291, Predicted: 2.354567050933838\n",
      "Actual: 9.006, Predicted: 7.972750663757324\n",
      "Actual: 13.351, Predicted: 13.784852981567383\n",
      "Actual: 14.144, Predicted: 14.233750343322754\n",
      "Actual: 14.37, Predicted: 14.430842399597168\n",
      "Actual: 6.377999999999999, Predicted: 6.44606351852417\n",
      "Actual: 9.584, Predicted: 9.931169509887695\n",
      "Actual: 14.255999999999998, Predicted: 14.582189559936523\n",
      "Actual: 1.966, Predicted: 2.454035520553589\n",
      "Actual: 13.514, Predicted: 13.549431800842285\n",
      "Actual: 4.259, Predicted: 4.208857536315918\n",
      "Actual: 2.713, Predicted: 2.701613187789917\n",
      "Actual: 12.153, Predicted: 12.361288070678711\n",
      "Actual: 9.281, Predicted: 9.861141204833984\n",
      "Actual: 11.763, Predicted: 12.094587326049805\n",
      "Actual: 4.016, Predicted: 3.9506642818450928\n",
      "Actual: 14.505, Predicted: 14.61812686920166\n",
      "Actual: 3.604, Predicted: 3.2485735416412354\n",
      "Actual: 3.921, Predicted: 4.0029401779174805\n",
      "Actual: 3.196, Predicted: 3.189899206161499\n",
      "Actual: 2.172, Predicted: 2.2140636444091797\n",
      "Actual: 9.516, Predicted: 9.619277954101562\n",
      "Actual: 14.231, Predicted: 14.314075469970703\n",
      "Actual: 11.685, Predicted: 11.822561264038086\n",
      "Actual: 11.354, Predicted: 11.760974884033203\n",
      "Actual: 3.071, Predicted: 2.8330018520355225\n",
      "Actual: 14.798, Predicted: 14.872610092163086\n",
      "Actual: 12.872, Predicted: 13.030728340148926\n",
      "Actual: 11.097, Predicted: 11.610566139221191\n",
      "Actual: 5.077, Predicted: 5.294271469116211\n",
      "Actual: 5.809, Predicted: 5.450714588165283\n",
      "Actual: 8.722000000000001, Predicted: 8.32567024230957\n",
      "Actual: 8.991999999999997, Predicted: 9.227599143981934\n",
      "Actual: 7.1560000000000015, Predicted: 7.488944053649902\n",
      "Actual: 3.832, Predicted: 3.6600515842437744\n",
      "Actual: 3.155, Predicted: 2.981584072113037\n",
      "Actual: 3.3360000000000003, Predicted: 3.3950650691986084\n",
      "Actual: 11.845, Predicted: 12.198473930358887\n",
      "Actual: 14.429, Predicted: 14.472586631774902\n",
      "Actual: 2.077, Predicted: 2.289476156234741\n",
      "Actual: 3.5, Predicted: 3.4841291904449463\n",
      "Actual: 11.729, Predicted: 12.03278923034668\n",
      "Actual: 3.092, Predicted: 3.1656835079193115\n",
      "Actual: 6.3, Predicted: 6.520185470581055\n",
      "Actual: 13.395, Predicted: 13.785052299499512\n",
      "Actual: 7.486999999999999, Predicted: 7.208157539367676\n",
      "Actual: 3.24, Predicted: 3.404589891433716\n",
      "Actual: 13.23, Predicted: 13.47662353515625\n",
      "Actual: 14.298, Predicted: 14.151289939880371\n",
      "Actual: 1.003, Predicted: 2.5927727222442627\n",
      "Actual: 2.7060000000000004, Predicted: 3.614983081817627\n",
      "Actual: 2.466, Predicted: 2.4753105640411377\n",
      "Actual: 2.611, Predicted: 3.0758492946624756\n",
      "Actual: 4.622, Predicted: 4.078925132751465\n",
      "Actual: 4.94, Predicted: 5.385863780975342\n",
      "Actual: 13.537, Predicted: 13.525712966918945\n",
      "Actual: 4.811, Predicted: 5.128631591796875\n",
      "Actual: 2.286, Predicted: 2.4473278522491455\n",
      "Actual: 3.8630000000000004, Predicted: 4.12549352645874\n",
      "Actual: 13.347, Predicted: 13.32519245147705\n",
      "Actual: 9.077, Predicted: 8.872050285339355\n",
      "Actual: 9.157, Predicted: 9.311700820922852\n",
      "Actual: 9.67, Predicted: 9.882781982421875\n",
      "Actual: 3.5, Predicted: 3.9298319816589355\n",
      "Actual: 11.759, Predicted: 11.57854175567627\n",
      "Actual: 13.505999999999998, Predicted: 13.896002769470215\n",
      "Actual: 11.386, Predicted: 11.723986625671387\n",
      "Actual: 14.122, Predicted: 14.192366600036621\n",
      "Actual: 14.408, Predicted: 14.572135925292969\n",
      "Actual: 11.743, Predicted: 11.786093711853027\n",
      "Actual: 11.235, Predicted: 11.247469902038574\n",
      "Actual: 11.284999999999998, Predicted: 11.384875297546387\n",
      "Actual: 4.059, Predicted: 4.174310684204102\n",
      "Actual: 5.399, Predicted: 5.536285877227783\n",
      "Actual: 6.205, Predicted: 6.2763519287109375\n",
      "Actual: 6.74, Predicted: 6.925114154815674\n",
      "Actual: 7.748999999999999, Predicted: 8.048184394836426\n",
      "Actual: 3.513, Predicted: 3.603435516357422\n",
      "Actual: 10.69, Predicted: 10.925914764404297\n",
      "Actual: 13.331, Predicted: 13.233817100524902\n",
      "Actual: 5.097, Predicted: 5.0722808837890625\n",
      "Actual: 13.713, Predicted: 13.868785858154297\n",
      "Actual: 1.941, Predicted: 2.3085684776306152\n",
      "Actual: 4.9190000000000005, Predicted: 5.409019470214844\n",
      "Actual: 13.557, Predicted: 13.62310791015625\n",
      "Actual: 2.71, Predicted: 2.8487677574157715\n",
      "Actual: 4.327999999999999, Predicted: 4.309061050415039\n",
      "Actual: 9.056, Predicted: 9.098732948303223\n",
      "Actual: 2.857, Predicted: 3.2142093181610107\n",
      "Actual: 5.272, Predicted: 4.930270195007324\n",
      "Actual: 4.6850000000000005, Predicted: 6.282325267791748\n",
      "Actual: 6.397, Predicted: 6.6914777755737305\n",
      "Actual: 7.185999999999999, Predicted: 7.163666248321533\n",
      "Actual: 13.484000000000002, Predicted: 13.941054344177246\n",
      "Actual: 14.223, Predicted: 14.426606178283691\n",
      "Actual: 10.611, Predicted: 10.575369834899902\n",
      "Actual: 9.627, Predicted: 9.993468284606934\n",
      "Actual: 3.14, Predicted: 4.7688703536987305\n",
      "Actual: 14.238, Predicted: 13.8487548828125\n",
      "Actual: 8.58, Predicted: 6.921629428863525\n",
      "Actual: 11.222, Predicted: 11.337376594543457\n",
      "Actual: 11.797, Predicted: 12.378698348999023\n",
      "Actual: 13.964, Predicted: 14.19223690032959\n",
      "Actual: 3.4560000000000004, Predicted: 3.4148519039154053\n",
      "Actual: 14.468, Predicted: 14.710409164428711\n",
      "Actual: 7.767999999999998, Predicted: 8.208964347839355\n",
      "Actual: 8.838, Predicted: 9.111934661865234\n",
      "Actual: 6.047999999999999, Predicted: 6.392291069030762\n",
      "Actual: 11.925, Predicted: 12.015810012817383\n",
      "Actual: 10.898, Predicted: 10.910635948181152\n",
      "Actual: 14.242, Predicted: 13.846653938293457\n",
      "Actual: 13.161, Predicted: 13.400665283203125\n",
      "Actual: 3.104, Predicted: 2.993840217590332\n",
      "Actual: 5.596, Predicted: 5.39453125\n",
      "Actual: 13.308, Predicted: 13.332831382751465\n",
      "Actual: 10.851, Predicted: 10.16586685180664\n",
      "Actual: 8.594999999999999, Predicted: 8.8573579788208\n",
      "Actual: 5.245, Predicted: 5.410036563873291\n",
      "Actual: 7.487, Predicted: 7.646623611450195\n",
      "Actual: 11.308, Predicted: 11.276436805725098\n",
      "Actual: 5.915, Predicted: 5.817923545837402\n",
      "Actual: 13.204, Predicted: 13.229222297668457\n",
      "Actual: 6.377999999999999, Predicted: 6.556003093719482\n",
      "Actual: 9.55, Predicted: 9.691277503967285\n",
      "Actual: 6.356, Predicted: 6.5489678382873535\n",
      "Actual: 3.333, Predicted: 3.1748101711273193\n",
      "Actual: 8.870999999999997, Predicted: 8.870757102966309\n",
      "Actual: 2.616, Predicted: 2.401841402053833\n",
      "Actual: 3.3960000000000004, Predicted: 3.407017469406128\n",
      "Actual: 2.989, Predicted: 2.886179208755493\n",
      "Actual: 3.33, Predicted: 3.3207592964172363\n",
      "Actual: 12.127999999999998, Predicted: 12.296931266784668\n",
      "Actual: 9.196, Predicted: 9.2776460647583\n",
      "Actual: 13.217, Predicted: 13.505971908569336\n",
      "Actual: 14.339, Predicted: 14.4886474609375\n",
      "Actual: 14.274, Predicted: 14.309576034545898\n",
      "Actual: 4.6, Predicted: 4.567162990570068\n",
      "Actual: 7.6839999999999975, Predicted: 7.67155647277832\n",
      "Actual: 9.021, Predicted: 9.1749849319458\n",
      "Actual: 13.531, Predicted: 13.66298770904541\n",
      "Actual: 13.577, Predicted: 13.752898216247559\n",
      "Actual: 3.005, Predicted: 3.168879747390747\n",
      "Actual: 15.212999999999997, Predicted: 15.324347496032715\n",
      "Actual: 12.146, Predicted: 12.583232879638672\n",
      "Actual: 7.617999999999999, Predicted: 7.9680304527282715\n",
      "Actual: 14.827, Predicted: 14.89687442779541\n",
      "Actual: 11.989999999999998, Predicted: 12.255166053771973\n",
      "Actual: 13.365, Predicted: 13.898037910461426\n",
      "Actual: 10.803, Predicted: 10.89510726928711\n",
      "Actual: 11.239, Predicted: 11.47916316986084\n",
      "Actual: 3.559, Predicted: 3.503432273864746\n",
      "Actual: 14.019, Predicted: 12.611602783203125\n",
      "Actual: 13.824000000000002, Predicted: 13.918521881103516\n",
      "Actual: 11.478, Predicted: 11.389599800109863\n",
      "Actual: 2.0540000000000003, Predicted: 2.1610779762268066\n",
      "Actual: 7.906999999999999, Predicted: 8.226068496704102\n",
      "Actual: 5.01, Predicted: 4.703298091888428\n",
      "Actual: 8.442, Predicted: 8.539658546447754\n",
      "Actual: 13.294, Predicted: 13.684181213378906\n",
      "Actual: 4.152, Predicted: 3.528170108795166\n",
      "Actual: 8.69, Predicted: 8.884434700012207\n",
      "Actual: 2.627, Predicted: 2.9095261096954346\n",
      "Actual: 9.378, Predicted: 9.519014358520508\n",
      "Actual: 13.77, Predicted: 14.163269996643066\n",
      "Actual: 4.222, Predicted: 4.401040077209473\n",
      "Actual: 14.226, Predicted: 13.961682319641113\n",
      "Actual: 9.12, Predicted: 9.328798294067383\n",
      "Actual: 3.069, Predicted: 3.491257429122925\n",
      "Actual: 4.257, Predicted: 4.5754499435424805\n",
      "Actual: 4.538, Predicted: 4.773834705352783\n",
      "Actual: 6.738, Predicted: 6.938326835632324\n",
      "Actual: 3.743, Predicted: 4.0084147453308105\n",
      "Actual: 14.06, Predicted: 14.16030216217041\n",
      "Actual: 15.160999999999998, Predicted: 15.209836959838867\n",
      "Actual: 11.977, Predicted: 11.80935001373291\n",
      "Actual: 3.457, Predicted: 4.822868347167969\n",
      "Actual: 4.31, Predicted: 4.718690395355225\n",
      "Actual: 13.113, Predicted: 13.057573318481445\n",
      "Actual: 2.226, Predicted: 4.3342695236206055\n",
      "Actual: 13.765, Predicted: 14.09194564819336\n",
      "Actual: 2.376, Predicted: 2.4489035606384277\n",
      "Actual: 7.994, Predicted: 7.8206353187561035\n",
      "Actual: 3.039, Predicted: 2.937171459197998\n",
      "Actual: 14.145, Predicted: 14.202537536621094\n",
      "Actual: 11.771999999999998, Predicted: 11.752646446228027\n",
      "Actual: 14.351, Predicted: 14.329215049743652\n",
      "Actual: 8.535, Predicted: 9.683419227600098\n",
      "Actual: 5.731, Predicted: 5.9012556076049805\n",
      "Actual: 12.039, Predicted: 12.51156997680664\n",
      "Actual: 2.506, Predicted: 2.661121129989624\n",
      "Actual: 8.247, Predicted: 8.56394100189209\n",
      "Actual: 10.53, Predicted: 10.89185619354248\n",
      "Actual: 3.687, Predicted: 3.646442413330078\n",
      "Actual: 3.766, Predicted: 3.904865026473999\n",
      "Actual: 3.7780000000000005, Predicted: 3.8443691730499268\n",
      "Actual: 13.932, Predicted: 14.191516876220703\n",
      "Actual: 8.366, Predicted: 8.577014923095703\n",
      "Actual: 3.8220000000000005, Predicted: 3.8296239376068115\n",
      "Actual: 5.973, Predicted: 5.7716593742370605\n",
      "Actual: 14.512, Predicted: 14.416136741638184\n",
      "Actual: 5.247000000000001, Predicted: 5.372784614562988\n",
      "Actual: 11.338, Predicted: 11.644493103027344\n",
      "Actual: 3.74, Predicted: 3.6913933753967285\n",
      "Actual: 5.827999999999999, Predicted: 5.848014831542969\n",
      "Actual: 3.39, Predicted: 3.1755459308624268\n",
      "Actual: 2.862, Predicted: 3.0639119148254395\n",
      "Actual: 13.297, Predicted: 13.485291481018066\n",
      "Actual: 2.9560000000000004, Predicted: 3.042281150817871\n",
      "Actual: 8.892000000000001, Predicted: 9.087334632873535\n",
      "Actual: 14.742, Predicted: 14.74629020690918\n",
      "Actual: 11.71, Predicted: 11.709783554077148\n",
      "Actual: 11.861999999999998, Predicted: 12.265097618103027\n",
      "Actual: 1.551, Predicted: 2.096024751663208\n",
      "Actual: 7.635999999999999, Predicted: 7.720351696014404\n",
      "Actual: 13.698, Predicted: 13.88725757598877\n",
      "Actual: 13.678, Predicted: 13.692174911499023\n",
      "Actual: 13.153, Predicted: 13.602179527282715\n",
      "Actual: 13.691, Predicted: 13.845136642456055\n",
      "Actual: 2.402, Predicted: 2.0836002826690674\n",
      "Actual: 12.199000000000002, Predicted: 12.470495223999023\n",
      "Actual: 4.506, Predicted: 4.345204830169678\n",
      "Actual: 13.298, Predicted: 13.390156745910645\n",
      "Actual: 14.231, Predicted: 14.267690658569336\n",
      "Actual: 8.738, Predicted: 8.164863586425781\n",
      "Actual: 8.679, Predicted: 8.773777961730957\n",
      "Actual: 4.038, Predicted: 4.369009017944336\n",
      "Actual: 14.09, Predicted: 14.22821044921875\n",
      "Actual: 13.214, Predicted: 13.670001983642578\n",
      "Actual: 3.898, Predicted: 3.7463440895080566\n",
      "Actual: 13.488, Predicted: 13.59339714050293\n",
      "Actual: 2.008, Predicted: 2.219865560531616\n",
      "Actual: 9.367, Predicted: 9.509190559387207\n",
      "Actual: 5.671, Predicted: 5.972942352294922\n",
      "Actual: 8.865, Predicted: 8.662108421325684\n",
      "Actual: 13.442, Predicted: 13.63900089263916\n",
      "Actual: 9.232, Predicted: 9.590944290161133\n",
      "Actual: 11.954, Predicted: 12.19939136505127\n",
      "Actual: 12.406, Predicted: 12.549647331237793\n",
      "Actual: 8.173, Predicted: 8.400493621826172\n",
      "Actual: 11.946, Predicted: 12.22347640991211\n",
      "Actual: 13.434, Predicted: 13.702369689941406\n",
      "Actual: 4.9990000000000006, Predicted: 5.120784282684326\n",
      "Actual: 6.814, Predicted: 7.128560543060303\n",
      "Actual: 5.4510000000000005, Predicted: 5.5864481925964355\n",
      "Actual: 7.76, Predicted: 7.5581254959106445\n",
      "Actual: 5.318, Predicted: 4.78061056137085\n",
      "Actual: 8.445, Predicted: 8.42844295501709\n",
      "Actual: 14.139, Predicted: 14.23070240020752\n",
      "Actual: 2.609, Predicted: 2.829587936401367\n",
      "Actual: 6.183, Predicted: 6.521188259124756\n",
      "Actual: 14.31, Predicted: 14.505696296691895\n",
      "Actual: 14.151, Predicted: 14.606185913085938\n",
      "Actual: 3.491, Predicted: 3.617574691772461\n",
      "Actual: 4.421, Predicted: 4.750156402587891\n",
      "Actual: 13.836, Predicted: 13.846151351928711\n",
      "Actual: 9.238, Predicted: 9.378608703613281\n",
      "Actual: 5.952000000000001, Predicted: 6.090733528137207\n",
      "Actual: 5.093, Predicted: 4.527894020080566\n",
      "Actual: 13.223, Predicted: 13.2597017288208\n",
      "Actual: 4.922, Predicted: 4.559518814086914\n",
      "Actual: 7.561999999999998, Predicted: 7.820977687835693\n",
      "Actual: 11.62, Predicted: 11.701600074768066\n",
      "Actual: 13.547, Predicted: 13.377248764038086\n",
      "Actual: 12.03, Predicted: 12.1094970703125\n",
      "Actual: 14.004, Predicted: 14.013773918151855\n",
      "Actual: 4.704, Predicted: 4.777318000793457\n",
      "Actual: 4.026, Predicted: 3.9874119758605957\n",
      "Actual: 8.588999999999999, Predicted: 8.786182403564453\n",
      "Actual: 2.905, Predicted: 2.98915696144104\n",
      "Actual: 14.349, Predicted: 14.441133499145508\n",
      "Actual: 8.434, Predicted: 9.015229225158691\n",
      "Actual: 13.296, Predicted: 13.23586368560791\n",
      "Actual: 3.265, Predicted: 3.1725363731384277\n",
      "Actual: 14.059, Predicted: 14.291494369506836\n",
      "Actual: 11.665, Predicted: 11.51708984375\n",
      "Actual: 11.867, Predicted: 12.168387413024902\n",
      "Actual: 13.475, Predicted: 13.610032081604004\n",
      "Actual: 8.097999999999999, Predicted: 8.23109245300293\n",
      "Actual: 13.789, Predicted: 14.033796310424805\n",
      "Actual: 2.492, Predicted: 2.8468658924102783\n",
      "Actual: 3.7850000000000006, Predicted: 3.4878432750701904\n",
      "Actual: 13.896, Predicted: 14.175503730773926\n",
      "Actual: 5.405, Predicted: 5.63873815536499\n",
      "Actual: 13.478, Predicted: 13.659557342529297\n",
      "Actual: 2.9410000000000003, Predicted: 3.0362625122070312\n",
      "Actual: 2.6790000000000003, Predicted: 2.827672004699707\n",
      "Actual: 5.524, Predicted: 5.675605297088623\n",
      "Actual: 13.769, Predicted: 13.954362869262695\n",
      "Actual: 9.096, Predicted: 8.663459777832031\n",
      "Actual: 2.71, Predicted: 2.663980007171631\n",
      "Actual: 12.03, Predicted: 12.248196601867676\n",
      "Actual: 2.082, Predicted: 2.036587953567505\n"
     ]
    }
   ],
   "source": [
    "# Compare predictions with actual values\n",
    "actual = scaler_y.inverse_transform(y_test_scaled)\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"Actual: {actual[i][0]}, Predicted: {predictions[i][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41e6359-94e8-460d-8646-261b747ec044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.24344677739633364\n",
      "Mean Squared Error (MSE): 0.1440171438839742\n",
      "Root Mean Squared Error (RMSE): 0.37949590759845386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(actual, predictions)\n",
    "mse = mean_squared_error(actual, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
