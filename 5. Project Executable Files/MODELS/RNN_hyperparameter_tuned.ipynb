{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca5a5499-930a-4bfb-806e-330937616574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout, Input\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b99487b9-cf34-45cd-85ca-6fdd53eb6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV file\n",
    "file_path = 'GlobalTemperatures.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Impute LandAverageTemperature and LandAverageTemperatureUncertainty with mean\n",
    "df['LandAverageTemperature'].fillna(df['LandAverageTemperature'].mean(), inplace=True)\n",
    "df['LandAverageTemperatureUncertainty'].fillna(df['LandAverageTemperatureUncertainty'].mean(), inplace=True)\n",
    "\n",
    "# For columns with 1200 missing values, drop those rows\n",
    "cols_to_dropna = ['LandMaxTemperature', 'LandMaxTemperatureUncertainty', 'LandMinTemperature', 'LandMinTemperatureUncertainty', 'LandAndOceanAverageTemperature', 'LandAndOceanAverageTemperatureUncertainty']\n",
    "df.dropna(subset=cols_to_dropna, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63bd3778-f278-47ac-b08b-6c85c12ba48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1593, 9, 1)\n",
      "X_test_scaled shape: (399, 9, 1)\n",
      "y_train_scaled shape: (1593, 1)\n",
      "y_test_scaled shape: (399, 1)\n"
     ]
    }
   ],
   "source": [
    "# Add Year and Month columns based on 'dt' column\n",
    "df['Year'] = pd.to_datetime(df['dt']).dt.year\n",
    "df['Month'] = pd.to_datetime(df['dt']).dt.month\n",
    "\n",
    "# Prepare X (features) and y (target)\n",
    "X = df.drop(['LandAverageTemperature', 'dt'], axis=1)\n",
    "y = df['LandAverageTemperature']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale X and y using MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler_x.fit_transform(X_train)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "# Only transform the testing data\n",
    "X_test_scaled = scaler_x.transform(X_test)\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Reshape X_train_scaled and X_test_scaled for RNN input\n",
    "X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"X_test_scaled shape:\", X_test_scaled.shape)\n",
    "print(\"y_train_scaled shape:\", y_train_scaled.shape)\n",
    "print(\"y_test_scaled shape:\", y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1518f7e2-4ad9-4e86-b4be-014f0bf1a462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END .........dropout_rate=0.1, optimizer=adam, units=50; total time=   2.3s\n",
      "[CV] END .........dropout_rate=0.1, optimizer=adam, units=50; total time=   2.2s\n",
      "[CV] END .........dropout_rate=0.1, optimizer=adam, units=50; total time=   2.4s\n",
      "[CV] END ........dropout_rate=0.1, optimizer=adam, units=100; total time=   2.3s\n",
      "[CV] END ........dropout_rate=0.1, optimizer=adam, units=100; total time=   2.3s\n",
      "[CV] END ........dropout_rate=0.1, optimizer=adam, units=100; total time=   2.4s\n",
      "[CV] END ........dropout_rate=0.2, optimizer=adam, units=150; total time=   2.2s\n",
      "[CV] END ........dropout_rate=0.2, optimizer=adam, units=150; total time=   2.2s\n",
      "[CV] END ........dropout_rate=0.2, optimizer=adam, units=150; total time=   2.2s\n",
      "[CV] END .....dropout_rate=0.1, optimizer=rmsprop, units=150; total time=   2.7s\n",
      "[CV] END .....dropout_rate=0.1, optimizer=rmsprop, units=150; total time=   2.1s\n",
      "[CV] END .....dropout_rate=0.1, optimizer=rmsprop, units=150; total time=   2.1s\n",
      "[CV] END ......dropout_rate=0.1, optimizer=rmsprop, units=50; total time=   2.1s\n",
      "[CV] END ......dropout_rate=0.1, optimizer=rmsprop, units=50; total time=   2.0s\n",
      "[CV] END ......dropout_rate=0.1, optimizer=rmsprop, units=50; total time=   2.4s\n",
      "[CV] END ........dropout_rate=0.3, optimizer=adam, units=100; total time=   2.1s\n",
      "[CV] END ........dropout_rate=0.3, optimizer=adam, units=100; total time=   2.1s\n",
      "[CV] END ........dropout_rate=0.3, optimizer=adam, units=100; total time=   2.1s\n",
      "[CV] END .....dropout_rate=0.3, optimizer=rmsprop, units=100; total time=   2.0s\n",
      "[CV] END .....dropout_rate=0.3, optimizer=rmsprop, units=100; total time=   2.1s\n",
      "[CV] END .....dropout_rate=0.3, optimizer=rmsprop, units=100; total time=   2.5s\n",
      "[CV] END ......dropout_rate=0.3, optimizer=rmsprop, units=50; total time=   2.1s\n",
      "[CV] END ......dropout_rate=0.3, optimizer=rmsprop, units=50; total time=   2.0s\n",
      "[CV] END ......dropout_rate=0.3, optimizer=rmsprop, units=50; total time=   2.1s\n",
      "[CV] END .....dropout_rate=0.2, optimizer=rmsprop, units=150; total time=   2.1s\n",
      "[CV] END .....dropout_rate=0.2, optimizer=rmsprop, units=150; total time=   2.1s\n",
      "[CV] END .....dropout_rate=0.2, optimizer=rmsprop, units=150; total time=   2.6s\n",
      "[CV] END ........dropout_rate=0.1, optimizer=adam, units=150; total time=   2.1s\n",
      "[CV] END ........dropout_rate=0.1, optimizer=adam, units=150; total time=   2.1s\n",
      "[CV] END ........dropout_rate=0.1, optimizer=adam, units=150; total time=   2.1s\n",
      "Best parameters found:  {'units': 150, 'optimizer': 'rmsprop', 'dropout_rate': 0.1}\n",
      "Best CV score:  0.9824242306644427\n",
      "Test loss:  0.9923981237683253\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout, Input\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to create the model\n",
    "def create_rnn_model(optimizer='adam', dropout_rate=0.2, units=100):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "    model.add(SimpleRNN(units, activation='relu', return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(SimpleRNN(units, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model\n",
    "\n",
    "# Wrap the Keras model so it can be used by sklearn\n",
    "model = KerasRegressor(build_fn=create_rnn_model, verbose=0,units=50,dropout_rate=0.1)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.1, 0.2, 0.3],\n",
    "    'units': [50, 100, 150]\n",
    "}\n",
    "\n",
    "# Setup random search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                                   n_iter=10, cv=3, verbose=2, random_state=42)\n",
    "\n",
    "# Perform the random search\n",
    "random_search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best CV score: \", random_search.best_score_)\n",
    "\n",
    "# Use the best model found\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on test data if available\n",
    "test_loss = best_model.score(X_test_scaled, y_test_scaled)\n",
    "print(\"Test loss: \", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f061147a-db3e-4c3a-a27d-730b5ae78164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 - 2s - 49ms/step - loss: 0.1045 - val_loss: 0.0166\n",
      "Epoch 2/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0161 - val_loss: 0.0013\n",
      "Epoch 3/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0095 - val_loss: 8.8955e-04\n",
      "Epoch 4/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0071 - val_loss: 9.6618e-04\n",
      "Epoch 5/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0064 - val_loss: 5.1898e-04\n",
      "Epoch 6/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0064 - val_loss: 0.0015\n",
      "Epoch 7/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 8/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0055 - val_loss: 5.8668e-04\n",
      "Epoch 9/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0052 - val_loss: 0.0012\n",
      "Epoch 10/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0044 - val_loss: 5.1208e-04\n",
      "Epoch 11/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0039 - val_loss: 2.9348e-04\n",
      "Epoch 12/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0038 - val_loss: 5.6459e-04\n",
      "Epoch 13/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0037 - val_loss: 3.7395e-04\n",
      "Epoch 14/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0034 - val_loss: 4.1189e-04\n",
      "Epoch 15/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0037 - val_loss: 3.0933e-04\n",
      "Epoch 16/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 17/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0036 - val_loss: 0.0010\n",
      "Epoch 18/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0037 - val_loss: 7.0276e-04\n",
      "Epoch 19/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0035 - val_loss: 2.1968e-04\n",
      "Epoch 20/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0033 - val_loss: 2.8900e-04\n",
      "Epoch 21/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0031 - val_loss: 2.8160e-04\n",
      "Epoch 22/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0029 - val_loss: 2.8256e-04\n",
      "Epoch 23/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0032 - val_loss: 4.1231e-04\n",
      "Epoch 24/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 25/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0028 - val_loss: 3.8285e-04\n",
      "Epoch 26/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0026 - val_loss: 2.2241e-04\n",
      "Epoch 27/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0026 - val_loss: 3.2624e-04\n",
      "Epoch 28/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0028 - val_loss: 3.2854e-04\n",
      "Epoch 29/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0026 - val_loss: 2.4065e-04\n",
      "Epoch 30/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0026 - val_loss: 6.4665e-04\n",
      "Epoch 31/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 32/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 33/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 34/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0027 - val_loss: 2.3963e-04\n",
      "Epoch 35/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0025 - val_loss: 2.0828e-04\n",
      "Epoch 36/100\n",
      "40/40 - 0s - 5ms/step - loss: 0.0024 - val_loss: 2.4911e-04\n",
      "Epoch 37/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0025 - val_loss: 1.9638e-04\n",
      "Epoch 38/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0023 - val_loss: 2.3858e-04\n",
      "Epoch 39/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0023 - val_loss: 2.6962e-04\n",
      "Epoch 40/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0022 - val_loss: 4.2340e-04\n",
      "Epoch 41/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0026 - val_loss: 2.0734e-04\n",
      "Epoch 42/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0021 - val_loss: 3.6584e-04\n",
      "Epoch 43/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0023 - val_loss: 2.5203e-04\n",
      "Epoch 44/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0024 - val_loss: 3.7733e-04\n",
      "Epoch 45/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0022 - val_loss: 3.4485e-04\n",
      "Epoch 46/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0021 - val_loss: 5.0593e-04\n",
      "Epoch 47/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0020 - val_loss: 2.6999e-04\n",
      "Epoch 48/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0020 - val_loss: 3.6923e-04\n",
      "Epoch 49/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0022 - val_loss: 3.8028e-04\n",
      "Epoch 50/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0022 - val_loss: 2.0545e-04\n",
      "Epoch 51/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0019 - val_loss: 1.6606e-04\n",
      "Epoch 52/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0023 - val_loss: 5.8454e-04\n",
      "Epoch 53/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0021 - val_loss: 2.4596e-04\n",
      "Epoch 54/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0019 - val_loss: 2.5184e-04\n",
      "Epoch 55/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0019 - val_loss: 2.1533e-04\n",
      "Epoch 56/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0018 - val_loss: 1.9508e-04\n",
      "Epoch 57/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0017 - val_loss: 2.3930e-04\n",
      "Epoch 58/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0017 - val_loss: 8.6764e-04\n",
      "Epoch 59/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0019 - val_loss: 2.1291e-04\n",
      "Epoch 60/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0018 - val_loss: 1.9505e-04\n",
      "Epoch 61/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0019 - val_loss: 5.0669e-04\n",
      "Epoch 62/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0020 - val_loss: 2.0825e-04\n",
      "Epoch 63/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0016 - val_loss: 1.8855e-04\n",
      "Epoch 64/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0019 - val_loss: 4.8189e-04\n",
      "Epoch 65/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0017 - val_loss: 1.7930e-04\n",
      "Epoch 66/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0017 - val_loss: 2.1635e-04\n",
      "Epoch 67/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0023 - val_loss: 3.0420e-04\n",
      "Epoch 68/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 69/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0015 - val_loss: 7.6526e-04\n",
      "Epoch 70/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0016 - val_loss: 2.6925e-04\n",
      "Epoch 71/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0016 - val_loss: 2.5885e-04\n",
      "Epoch 72/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0015 - val_loss: 5.8514e-04\n",
      "Epoch 73/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0015 - val_loss: 3.6638e-04\n",
      "Epoch 74/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0016 - val_loss: 2.1688e-04\n",
      "Epoch 75/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0017 - val_loss: 5.1536e-04\n",
      "Epoch 76/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0015 - val_loss: 2.1622e-04\n",
      "Epoch 77/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0014 - val_loss: 2.9814e-04\n",
      "Epoch 78/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0014 - val_loss: 1.8629e-04\n",
      "Epoch 79/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0014 - val_loss: 3.3506e-04\n",
      "Epoch 80/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0014 - val_loss: 4.4682e-04\n",
      "Epoch 81/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0016 - val_loss: 1.7245e-04\n",
      "Epoch 82/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0014 - val_loss: 2.6578e-04\n",
      "Epoch 83/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0015 - val_loss: 3.4578e-04\n",
      "Epoch 84/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0014 - val_loss: 2.2778e-04\n",
      "Epoch 85/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0017 - val_loss: 2.9080e-04\n",
      "Epoch 86/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0013 - val_loss: 2.1673e-04\n",
      "Epoch 87/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0014 - val_loss: 2.0412e-04\n",
      "Epoch 88/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0013 - val_loss: 1.7923e-04\n",
      "Epoch 89/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0014 - val_loss: 3.4864e-04\n",
      "Epoch 90/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0013 - val_loss: 1.9919e-04\n",
      "Epoch 91/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0012 - val_loss: 2.4071e-04\n",
      "Epoch 92/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0012 - val_loss: 1.7397e-04\n",
      "Epoch 93/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0012 - val_loss: 2.4583e-04\n",
      "Epoch 94/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0013 - val_loss: 2.1826e-04\n",
      "Epoch 95/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0013 - val_loss: 1.7741e-04\n",
      "Epoch 96/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0014 - val_loss: 2.7658e-04\n",
      "Epoch 97/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0011 - val_loss: 2.0070e-04\n",
      "Epoch 98/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0014 - val_loss: 1.7360e-04\n",
      "Epoch 99/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0013 - val_loss: 4.6998e-04\n",
      "Epoch 100/100\n",
      "40/40 - 0s - 4ms/step - loss: 0.0012 - val_loss: 3.4183e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train_scaled, epochs=100, batch_size=32, validation_split=0.2, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589baada-df35-4060-badc-638702b6952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predictions = scaler_y.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f32349-d821-489b-ad08-1021d4ca8885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 3.88, Predicted: 3.7020914554595947\n",
      "Actual: 8.689, Predicted: 8.477648735046387\n",
      "Actual: 13.622, Predicted: 13.157889366149902\n",
      "Actual: 2.335, Predicted: 2.715528964996338\n",
      "Actual: 5.952999999999999, Predicted: 5.919629096984863\n",
      "Actual: 4.869, Predicted: 4.665404796600342\n",
      "Actual: 14.768, Predicted: 14.490358352661133\n",
      "Actual: 7.423999999999999, Predicted: 7.26339054107666\n",
      "Actual: 4.103, Predicted: 4.020365238189697\n",
      "Actual: 4.519, Predicted: 4.235733509063721\n",
      "Actual: 14.021, Predicted: 13.683463096618652\n",
      "Actual: 14.034, Predicted: 13.443159103393555\n",
      "Actual: 4.85, Predicted: 4.859615802764893\n",
      "Actual: 9.453, Predicted: 9.224322319030762\n",
      "Actual: 6.222, Predicted: 6.117021083831787\n",
      "Actual: 14.445, Predicted: 14.043622016906738\n",
      "Actual: 11.062, Predicted: 10.710625648498535\n",
      "Actual: 2.455, Predicted: 2.6483888626098633\n",
      "Actual: 6.273, Predicted: 6.213909149169922\n",
      "Actual: 4.303, Predicted: 4.252017021179199\n",
      "Actual: 5.066, Predicted: 5.344930648803711\n",
      "Actual: 10.941999999999998, Predicted: 10.716167449951172\n",
      "Actual: 4.859, Predicted: 4.835768699645996\n",
      "Actual: 3.629, Predicted: 3.8265044689178467\n",
      "Actual: 4.924, Predicted: 5.0211873054504395\n",
      "Actual: 12.048, Predicted: 11.807823181152344\n",
      "Actual: 13.157, Predicted: 12.593948364257812\n",
      "Actual: 10.944, Predicted: 10.55517864227295\n",
      "Actual: 9.264, Predicted: 9.016412734985352\n",
      "Actual: 8.498999999999999, Predicted: 8.322355270385742\n",
      "Actual: 5.902, Predicted: 5.666650295257568\n",
      "Actual: 13.775, Predicted: 13.43974781036377\n",
      "Actual: 2.488, Predicted: 2.681030750274658\n",
      "Actual: 3.628, Predicted: 3.863334894180298\n",
      "Actual: 14.201, Predicted: 13.946368217468262\n",
      "Actual: 13.22, Predicted: 13.007670402526855\n",
      "Actual: 5.186, Predicted: 5.89410924911499\n",
      "Actual: 9.338, Predicted: 9.093999862670898\n",
      "Actual: 3.422, Predicted: 3.644293785095215\n",
      "Actual: 5.118, Predicted: 4.898772716522217\n",
      "Actual: 13.687, Predicted: 13.437175750732422\n",
      "Actual: 3.069, Predicted: 2.9657998085021973\n",
      "Actual: 12.324000000000002, Predicted: 12.13698673248291\n",
      "Actual: 13.807, Predicted: 13.467472076416016\n",
      "Actual: 1.836, Predicted: 1.631210446357727\n",
      "Actual: 5.702000000000001, Predicted: 5.776334762573242\n",
      "Actual: 13.401, Predicted: 13.287562370300293\n",
      "Actual: 11.892, Predicted: 11.670621871948242\n",
      "Actual: 12.984000000000002, Predicted: 12.597469329833984\n",
      "Actual: 8.542, Predicted: 8.043451309204102\n",
      "Actual: 5.031000000000001, Predicted: 4.8844499588012695\n",
      "Actual: 11.514, Predicted: 11.675209045410156\n",
      "Actual: 4.8660000000000005, Predicted: 4.7987380027771\n",
      "Actual: 12.095999999999998, Predicted: 11.868735313415527\n",
      "Actual: 14.285, Predicted: 13.631983757019043\n",
      "Actual: 3.2430000000000003, Predicted: 3.326429605484009\n",
      "Actual: 9.735, Predicted: 9.251802444458008\n",
      "Actual: 8.511000000000001, Predicted: 8.29865837097168\n",
      "Actual: 12.856, Predicted: 12.617476463317871\n",
      "Actual: 14.144, Predicted: 13.618341445922852\n",
      "Actual: 3.656, Predicted: 3.6701221466064453\n",
      "Actual: 13.164, Predicted: 13.043925285339355\n",
      "Actual: 12.093, Predicted: 11.926618576049805\n",
      "Actual: 2.781, Predicted: 3.035663604736328\n",
      "Actual: 11.831, Predicted: 11.700182914733887\n",
      "Actual: 13.405, Predicted: 12.7156982421875\n",
      "Actual: 13.752, Predicted: 13.388121604919434\n",
      "Actual: 14.052, Predicted: 13.661073684692383\n",
      "Actual: 9.488, Predicted: 9.063350677490234\n",
      "Actual: 4.8260000000000005, Predicted: 4.750419616699219\n",
      "Actual: 13.807, Predicted: 13.446823120117188\n",
      "Actual: 5.89, Predicted: 5.712439060211182\n",
      "Actual: 4.959, Predicted: 4.766200542449951\n",
      "Actual: 14.392, Predicted: 14.164756774902344\n",
      "Actual: 8.25, Predicted: 7.665428161621094\n",
      "Actual: 14.742, Predicted: 14.176542282104492\n",
      "Actual: 8.443999999999999, Predicted: 7.771071434020996\n",
      "Actual: 3.1950000000000003, Predicted: 3.2808620929718018\n",
      "Actual: 11.604, Predicted: 11.36223316192627\n",
      "Actual: 13.105, Predicted: 12.802286148071289\n",
      "Actual: 13.412, Predicted: 13.084839820861816\n",
      "Actual: 7.9209999999999985, Predicted: 7.636770725250244\n",
      "Actual: 2.052, Predicted: 2.4271326065063477\n",
      "Actual: 3.5980000000000003, Predicted: 3.6607320308685303\n",
      "Actual: 14.138, Predicted: 13.630297660827637\n",
      "Actual: 14.375, Predicted: 14.071897506713867\n",
      "Actual: 9.552, Predicted: 9.313066482543945\n",
      "Actual: 4.134, Predicted: 4.0953369140625\n",
      "Actual: 11.155, Predicted: 11.058091163635254\n",
      "Actual: 9.729, Predicted: 9.588735580444336\n",
      "Actual: 3.306, Predicted: 3.3668324947357178\n",
      "Actual: 14.140999999999998, Predicted: 13.564929008483887\n",
      "Actual: 14.377, Predicted: 14.119810104370117\n",
      "Actual: 13.796, Predicted: 13.601967811584473\n",
      "Actual: 9.671, Predicted: 9.491010665893555\n",
      "Actual: 7.329999999999999, Predicted: 7.071404457092285\n",
      "Actual: 6.404, Predicted: 6.425687313079834\n",
      "Actual: 1.793, Predicted: 2.3130598068237305\n",
      "Actual: 10.787999999999998, Predicted: 10.719730377197266\n",
      "Actual: 14.630999999999998, Predicted: 14.231986999511719\n",
      "Actual: 14.188, Predicted: 13.968695640563965\n",
      "Actual: 7.738999999999999, Predicted: 7.363150596618652\n",
      "Actual: 2.228, Predicted: 3.0090444087982178\n",
      "Actual: 8.280999999999999, Predicted: 7.984232425689697\n",
      "Actual: 11.984000000000002, Predicted: 11.623496055603027\n",
      "Actual: 3.458, Predicted: 3.341632127761841\n",
      "Actual: 6.295, Predicted: 6.230274677276611\n",
      "Actual: 2.291, Predicted: 2.3000121116638184\n",
      "Actual: 9.006, Predicted: 8.122018814086914\n",
      "Actual: 13.351, Predicted: 12.99213695526123\n",
      "Actual: 14.144, Predicted: 13.773506164550781\n",
      "Actual: 14.37, Predicted: 14.004534721374512\n",
      "Actual: 6.377999999999999, Predicted: 6.013285160064697\n",
      "Actual: 9.584, Predicted: 9.270125389099121\n",
      "Actual: 14.255999999999998, Predicted: 14.105546951293945\n",
      "Actual: 1.966, Predicted: 2.457139253616333\n",
      "Actual: 13.514, Predicted: 13.334859848022461\n",
      "Actual: 4.259, Predicted: 4.046586513519287\n",
      "Actual: 2.713, Predicted: 2.838799238204956\n",
      "Actual: 12.153, Predicted: 11.89266300201416\n",
      "Actual: 9.281, Predicted: 9.016427993774414\n",
      "Actual: 11.763, Predicted: 11.712542533874512\n",
      "Actual: 4.016, Predicted: 3.938797950744629\n",
      "Actual: 14.505, Predicted: 14.220651626586914\n",
      "Actual: 3.604, Predicted: 3.4738361835479736\n",
      "Actual: 3.921, Predicted: 3.800968647003174\n",
      "Actual: 3.196, Predicted: 3.1098217964172363\n",
      "Actual: 2.172, Predicted: 2.4184741973876953\n",
      "Actual: 9.516, Predicted: 9.215404510498047\n",
      "Actual: 14.231, Predicted: 13.957039833068848\n",
      "Actual: 11.685, Predicted: 11.37939167022705\n",
      "Actual: 11.354, Predicted: 11.382308959960938\n",
      "Actual: 3.071, Predicted: 3.0829970836639404\n",
      "Actual: 14.798, Predicted: 14.422904014587402\n",
      "Actual: 12.872, Predicted: 12.502117156982422\n",
      "Actual: 11.097, Predicted: 10.876143455505371\n",
      "Actual: 5.077, Predicted: 4.983312606811523\n",
      "Actual: 5.809, Predicted: 4.899387836456299\n",
      "Actual: 8.722000000000001, Predicted: 8.48127555847168\n",
      "Actual: 8.991999999999997, Predicted: 8.901537895202637\n",
      "Actual: 7.1560000000000015, Predicted: 7.000705718994141\n",
      "Actual: 3.832, Predicted: 3.768909215927124\n",
      "Actual: 3.155, Predicted: 2.9783897399902344\n",
      "Actual: 3.3360000000000003, Predicted: 3.412529945373535\n",
      "Actual: 11.845, Predicted: 11.607022285461426\n",
      "Actual: 14.429, Predicted: 14.130749702453613\n",
      "Actual: 2.077, Predicted: 2.4687294960021973\n",
      "Actual: 3.5, Predicted: 3.4567434787750244\n",
      "Actual: 11.729, Predicted: 11.710227966308594\n",
      "Actual: 3.092, Predicted: 3.1309850215911865\n",
      "Actual: 6.3, Predicted: 6.073002815246582\n",
      "Actual: 13.395, Predicted: 12.822382926940918\n",
      "Actual: 7.486999999999999, Predicted: 7.57673978805542\n",
      "Actual: 3.24, Predicted: 3.357877492904663\n",
      "Actual: 13.23, Predicted: 12.852296829223633\n",
      "Actual: 14.298, Predicted: 13.755682945251465\n",
      "Actual: 1.003, Predicted: 1.4260801076889038\n",
      "Actual: 2.7060000000000004, Predicted: 3.086907386779785\n",
      "Actual: 2.466, Predicted: 2.658618927001953\n",
      "Actual: 2.611, Predicted: 2.58998966217041\n",
      "Actual: 4.622, Predicted: 4.414844036102295\n",
      "Actual: 4.94, Predicted: 4.832386016845703\n",
      "Actual: 13.537, Predicted: 12.81899642944336\n",
      "Actual: 4.811, Predicted: 4.658143520355225\n",
      "Actual: 2.286, Predicted: 2.3325066566467285\n",
      "Actual: 3.8630000000000004, Predicted: 4.015427112579346\n",
      "Actual: 13.347, Predicted: 12.937660217285156\n",
      "Actual: 9.077, Predicted: 8.713905334472656\n",
      "Actual: 9.157, Predicted: 8.940711975097656\n",
      "Actual: 9.67, Predicted: 9.312995910644531\n",
      "Actual: 3.5, Predicted: 3.7549896240234375\n",
      "Actual: 11.759, Predicted: 11.345064163208008\n",
      "Actual: 13.505999999999998, Predicted: 13.097027778625488\n",
      "Actual: 11.386, Predicted: 11.50185489654541\n",
      "Actual: 14.122, Predicted: 13.74737548828125\n",
      "Actual: 14.408, Predicted: 14.105545043945312\n",
      "Actual: 11.743, Predicted: 11.448060989379883\n",
      "Actual: 11.235, Predicted: 11.266545295715332\n",
      "Actual: 11.284999999999998, Predicted: 11.042513847351074\n",
      "Actual: 4.059, Predicted: 3.9932994842529297\n",
      "Actual: 5.399, Predicted: 5.149620056152344\n",
      "Actual: 6.205, Predicted: 6.079831123352051\n",
      "Actual: 6.74, Predicted: 6.614277362823486\n",
      "Actual: 7.748999999999999, Predicted: 7.478085994720459\n",
      "Actual: 3.513, Predicted: 3.6774957180023193\n",
      "Actual: 10.69, Predicted: 10.503241539001465\n",
      "Actual: 13.331, Predicted: 12.974505424499512\n",
      "Actual: 5.097, Predicted: 4.9892048835754395\n",
      "Actual: 13.713, Predicted: 13.42752742767334\n",
      "Actual: 1.941, Predicted: 1.6894397735595703\n",
      "Actual: 4.9190000000000005, Predicted: 4.752201080322266\n",
      "Actual: 13.557, Predicted: 13.222411155700684\n",
      "Actual: 2.71, Predicted: 2.915848970413208\n",
      "Actual: 4.327999999999999, Predicted: 4.090270519256592\n",
      "Actual: 9.056, Predicted: 8.697972297668457\n",
      "Actual: 2.857, Predicted: 3.1833746433258057\n",
      "Actual: 5.272, Predicted: 5.3255085945129395\n",
      "Actual: 4.6850000000000005, Predicted: 4.781680583953857\n",
      "Actual: 6.397, Predicted: 6.170687198638916\n",
      "Actual: 7.185999999999999, Predicted: 6.858702182769775\n",
      "Actual: 13.484000000000002, Predicted: 13.482848167419434\n",
      "Actual: 14.223, Predicted: 13.682751655578613\n",
      "Actual: 10.611, Predicted: 10.34406566619873\n",
      "Actual: 9.627, Predicted: 9.275222778320312\n",
      "Actual: 3.14, Predicted: 3.4873697757720947\n",
      "Actual: 14.238, Predicted: 13.486452102661133\n",
      "Actual: 8.58, Predicted: 8.04744815826416\n",
      "Actual: 11.222, Predicted: 10.998649597167969\n",
      "Actual: 11.797, Predicted: 11.447831153869629\n",
      "Actual: 13.964, Predicted: 13.772909164428711\n",
      "Actual: 3.4560000000000004, Predicted: 3.5914812088012695\n",
      "Actual: 14.468, Predicted: 14.235213279724121\n",
      "Actual: 7.767999999999998, Predicted: 8.01205062866211\n",
      "Actual: 8.838, Predicted: 8.50346565246582\n",
      "Actual: 6.047999999999999, Predicted: 6.075869560241699\n",
      "Actual: 11.925, Predicted: 11.693285942077637\n",
      "Actual: 10.898, Predicted: 10.304248809814453\n",
      "Actual: 14.242, Predicted: 13.579745292663574\n",
      "Actual: 13.161, Predicted: 12.935039520263672\n",
      "Actual: 3.104, Predicted: 3.0894477367401123\n",
      "Actual: 5.596, Predicted: 5.372744083404541\n",
      "Actual: 13.308, Predicted: 13.067493438720703\n",
      "Actual: 10.851, Predicted: 9.922825813293457\n",
      "Actual: 8.594999999999999, Predicted: 8.550149917602539\n",
      "Actual: 5.245, Predicted: 5.328123569488525\n",
      "Actual: 7.487, Predicted: 7.303252696990967\n",
      "Actual: 11.308, Predicted: 11.119195938110352\n",
      "Actual: 5.915, Predicted: 5.897672653198242\n",
      "Actual: 13.204, Predicted: 12.996465682983398\n",
      "Actual: 6.377999999999999, Predicted: 6.371665954589844\n",
      "Actual: 9.55, Predicted: 9.227842330932617\n",
      "Actual: 6.356, Predicted: 6.155875205993652\n",
      "Actual: 3.333, Predicted: 3.4003705978393555\n",
      "Actual: 8.870999999999997, Predicted: 8.734686851501465\n",
      "Actual: 2.616, Predicted: 2.8106534481048584\n",
      "Actual: 3.3960000000000004, Predicted: 3.571018934249878\n",
      "Actual: 2.989, Predicted: 3.1421308517456055\n",
      "Actual: 3.33, Predicted: 3.520939588546753\n",
      "Actual: 12.127999999999998, Predicted: 11.91907024383545\n",
      "Actual: 9.196, Predicted: 8.803293228149414\n",
      "Actual: 13.217, Predicted: 13.393089294433594\n",
      "Actual: 14.339, Predicted: 13.77034854888916\n",
      "Actual: 14.274, Predicted: 13.67871379852295\n",
      "Actual: 4.6, Predicted: 4.329107284545898\n",
      "Actual: 7.6839999999999975, Predicted: 7.291720390319824\n",
      "Actual: 9.021, Predicted: 8.685144424438477\n",
      "Actual: 13.531, Predicted: 13.29357624053955\n",
      "Actual: 13.577, Predicted: 13.209638595581055\n",
      "Actual: 3.005, Predicted: 3.0857818126678467\n",
      "Actual: 15.212999999999997, Predicted: 14.901981353759766\n",
      "Actual: 12.146, Predicted: 11.76937484741211\n",
      "Actual: 7.617999999999999, Predicted: 7.55037260055542\n",
      "Actual: 14.827, Predicted: 14.437250137329102\n",
      "Actual: 11.989999999999998, Predicted: 11.65536880493164\n",
      "Actual: 13.365, Predicted: 13.260754585266113\n",
      "Actual: 10.803, Predicted: 10.621519088745117\n",
      "Actual: 11.239, Predicted: 10.9517183303833\n",
      "Actual: 3.559, Predicted: 3.618469715118408\n",
      "Actual: 14.019, Predicted: 13.30018138885498\n",
      "Actual: 13.824000000000002, Predicted: 13.499781608581543\n",
      "Actual: 11.478, Predicted: 11.700470924377441\n",
      "Actual: 2.0540000000000003, Predicted: 2.268913984298706\n",
      "Actual: 7.906999999999999, Predicted: 7.892226219177246\n",
      "Actual: 5.01, Predicted: 5.101295471191406\n",
      "Actual: 8.442, Predicted: 8.133781433105469\n",
      "Actual: 13.294, Predicted: 13.097908973693848\n",
      "Actual: 4.152, Predicted: 3.655996084213257\n",
      "Actual: 8.69, Predicted: 8.429787635803223\n",
      "Actual: 2.627, Predicted: 2.7088029384613037\n",
      "Actual: 9.378, Predicted: 9.045321464538574\n",
      "Actual: 13.77, Predicted: 13.613142967224121\n",
      "Actual: 4.222, Predicted: 4.251581192016602\n",
      "Actual: 14.226, Predicted: 13.629667282104492\n",
      "Actual: 9.12, Predicted: 8.771618843078613\n",
      "Actual: 3.069, Predicted: 2.638188123703003\n",
      "Actual: 4.257, Predicted: 4.2809014320373535\n",
      "Actual: 4.538, Predicted: 5.252281188964844\n",
      "Actual: 6.738, Predicted: 6.587949275970459\n",
      "Actual: 3.743, Predicted: 3.8706142902374268\n",
      "Actual: 14.06, Predicted: 13.711674690246582\n",
      "Actual: 15.160999999999998, Predicted: 14.7835054397583\n",
      "Actual: 11.977, Predicted: 11.610249519348145\n",
      "Actual: 3.457, Predicted: 3.052135944366455\n",
      "Actual: 4.31, Predicted: 4.409523963928223\n",
      "Actual: 13.113, Predicted: 12.719051361083984\n",
      "Actual: 2.226, Predicted: 2.6409902572631836\n",
      "Actual: 13.765, Predicted: 13.452592849731445\n",
      "Actual: 2.376, Predicted: 2.6610329151153564\n",
      "Actual: 7.994, Predicted: 7.429769039154053\n",
      "Actual: 3.039, Predicted: 3.1732125282287598\n",
      "Actual: 14.145, Predicted: 13.78404426574707\n",
      "Actual: 11.771999999999998, Predicted: 11.467764854431152\n",
      "Actual: 14.351, Predicted: 13.912774085998535\n",
      "Actual: 8.535, Predicted: 7.446767807006836\n",
      "Actual: 5.731, Predicted: 5.693113803863525\n",
      "Actual: 12.039, Predicted: 11.923602104187012\n",
      "Actual: 2.506, Predicted: 2.8764212131500244\n",
      "Actual: 8.247, Predicted: 7.980563163757324\n",
      "Actual: 10.53, Predicted: 10.658689498901367\n",
      "Actual: 3.687, Predicted: 3.715740203857422\n",
      "Actual: 3.766, Predicted: 3.848592758178711\n",
      "Actual: 3.7780000000000005, Predicted: 3.846047878265381\n",
      "Actual: 13.932, Predicted: 13.66489315032959\n",
      "Actual: 8.366, Predicted: 8.187006950378418\n",
      "Actual: 3.8220000000000005, Predicted: 3.8105180263519287\n",
      "Actual: 5.973, Predicted: 5.740584850311279\n",
      "Actual: 14.512, Predicted: 14.225504875183105\n",
      "Actual: 5.247000000000001, Predicted: 5.076377868652344\n",
      "Actual: 11.338, Predicted: 11.061552047729492\n",
      "Actual: 3.74, Predicted: 3.7399861812591553\n",
      "Actual: 5.827999999999999, Predicted: 5.875769138336182\n",
      "Actual: 3.39, Predicted: 3.391514778137207\n",
      "Actual: 2.862, Predicted: 3.062082529067993\n",
      "Actual: 13.297, Predicted: 12.984452247619629\n",
      "Actual: 2.9560000000000004, Predicted: 3.1311707496643066\n",
      "Actual: 8.892000000000001, Predicted: 8.816170692443848\n",
      "Actual: 14.742, Predicted: 14.461058616638184\n",
      "Actual: 11.71, Predicted: 11.791095733642578\n",
      "Actual: 11.861999999999998, Predicted: 11.716231346130371\n",
      "Actual: 1.551, Predicted: 1.5525577068328857\n",
      "Actual: 7.635999999999999, Predicted: 7.700320243835449\n",
      "Actual: 13.698, Predicted: 13.419450759887695\n",
      "Actual: 13.678, Predicted: 13.36031723022461\n",
      "Actual: 13.153, Predicted: 12.840808868408203\n",
      "Actual: 13.691, Predicted: 13.451789855957031\n",
      "Actual: 2.402, Predicted: 2.3051950931549072\n",
      "Actual: 12.199000000000002, Predicted: 12.002649307250977\n",
      "Actual: 4.506, Predicted: 4.56044340133667\n",
      "Actual: 13.298, Predicted: 12.815162658691406\n",
      "Actual: 14.231, Predicted: 13.670015335083008\n",
      "Actual: 8.738, Predicted: 8.545811653137207\n",
      "Actual: 8.679, Predicted: 8.3933744430542\n",
      "Actual: 4.038, Predicted: 4.138514518737793\n",
      "Actual: 14.09, Predicted: 13.766357421875\n",
      "Actual: 13.214, Predicted: 12.983135223388672\n",
      "Actual: 3.898, Predicted: 3.993513345718384\n",
      "Actual: 13.488, Predicted: 13.141251564025879\n",
      "Actual: 2.008, Predicted: 2.4937031269073486\n",
      "Actual: 9.367, Predicted: 9.001554489135742\n",
      "Actual: 5.671, Predicted: 5.426053047180176\n",
      "Actual: 8.865, Predicted: 8.503962516784668\n",
      "Actual: 13.442, Predicted: 13.313060760498047\n",
      "Actual: 9.232, Predicted: 9.04389476776123\n",
      "Actual: 11.954, Predicted: 11.716700553894043\n",
      "Actual: 12.406, Predicted: 12.184549331665039\n",
      "Actual: 8.173, Predicted: 8.022771835327148\n",
      "Actual: 11.946, Predicted: 11.744806289672852\n",
      "Actual: 13.434, Predicted: 12.989011764526367\n",
      "Actual: 4.9990000000000006, Predicted: 5.179551601409912\n",
      "Actual: 6.814, Predicted: 6.672717571258545\n",
      "Actual: 5.4510000000000005, Predicted: 5.425414562225342\n",
      "Actual: 7.76, Predicted: 7.687141418457031\n",
      "Actual: 5.318, Predicted: 5.263272762298584\n",
      "Actual: 8.445, Predicted: 8.503814697265625\n",
      "Actual: 14.139, Predicted: 13.826902389526367\n",
      "Actual: 2.609, Predicted: 2.877992630004883\n",
      "Actual: 6.183, Predicted: 6.003127098083496\n",
      "Actual: 14.31, Predicted: 13.863253593444824\n",
      "Actual: 14.151, Predicted: 14.018542289733887\n",
      "Actual: 3.491, Predicted: 3.532069444656372\n",
      "Actual: 4.421, Predicted: 4.594648838043213\n",
      "Actual: 13.836, Predicted: 13.417007446289062\n",
      "Actual: 9.238, Predicted: 8.876177787780762\n",
      "Actual: 5.952000000000001, Predicted: 5.898691654205322\n",
      "Actual: 5.093, Predicted: 4.878106594085693\n",
      "Actual: 13.223, Predicted: 12.898597717285156\n",
      "Actual: 4.922, Predicted: 4.890801429748535\n",
      "Actual: 7.561999999999998, Predicted: 7.260376453399658\n",
      "Actual: 11.62, Predicted: 11.468024253845215\n",
      "Actual: 13.547, Predicted: 13.036096572875977\n",
      "Actual: 12.03, Predicted: 11.63498306274414\n",
      "Actual: 14.004, Predicted: 13.523561477661133\n",
      "Actual: 4.704, Predicted: 4.564182281494141\n",
      "Actual: 4.026, Predicted: 3.951244831085205\n",
      "Actual: 8.588999999999999, Predicted: 8.504390716552734\n",
      "Actual: 2.905, Predicted: 3.1443698406219482\n",
      "Actual: 14.349, Predicted: 13.929035186767578\n",
      "Actual: 8.434, Predicted: 8.389766693115234\n",
      "Actual: 13.296, Predicted: 12.93356704711914\n",
      "Actual: 3.265, Predicted: 3.3478500843048096\n",
      "Actual: 14.059, Predicted: 13.851573944091797\n",
      "Actual: 11.665, Predicted: 11.255327224731445\n",
      "Actual: 11.867, Predicted: 11.7357177734375\n",
      "Actual: 13.475, Predicted: 13.244732856750488\n",
      "Actual: 8.097999999999999, Predicted: 7.9898762702941895\n",
      "Actual: 13.789, Predicted: 13.4685640335083\n",
      "Actual: 2.492, Predicted: 2.833446502685547\n",
      "Actual: 3.7850000000000006, Predicted: 3.859074831008911\n",
      "Actual: 13.896, Predicted: 13.800995826721191\n",
      "Actual: 5.405, Predicted: 5.27940034866333\n",
      "Actual: 13.478, Predicted: 13.30001449584961\n",
      "Actual: 2.9410000000000003, Predicted: 3.0717673301696777\n",
      "Actual: 2.6790000000000003, Predicted: 2.8777990341186523\n",
      "Actual: 5.524, Predicted: 5.50378942489624\n",
      "Actual: 13.769, Predicted: 13.470525741577148\n",
      "Actual: 9.096, Predicted: 8.514083862304688\n",
      "Actual: 2.71, Predicted: 2.8081130981445312\n",
      "Actual: 12.03, Predicted: 11.794944763183594\n",
      "Actual: 2.082, Predicted: 2.139810562133789\n"
     ]
    }
   ],
   "source": [
    "# Compare predictions with actual values\n",
    "actual = scaler_y.inverse_transform(y_test_scaled)\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"Actual: {actual[i][0]}, Predicted: {predictions[i][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13167292-bb8c-4f58-83c6-985362224888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.2504194186456818\n",
      "Mean Squared Error (MSE): 0.09297780483165861\n",
      "Root Mean Squared Error (RMSE): 0.30492262105599616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(actual, predictions)\n",
    "mse = mean_squared_error(actual, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
